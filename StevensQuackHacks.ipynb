{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "43243363-05cc-45b9-a802-41ef4b8e818a",
     "showTitle": false,
     "tableResultSettingsMap": {},
     "title": ""
    }
   },
   "outputs": [
    {
     "output_type": "stream",
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Requirement already satisfied: dbdemos in /local_disk0/.ephemeral_nfs/envs/pythonEnv-0d2a3b85-99ec-42fc-ab7b-cd12f20dadd4/lib/python3.11/site-packages (0.6.13)\nRequirement already satisfied: requests in /databricks/python3/lib/python3.11/site-packages (from dbdemos) (2.31.0)\nRequirement already satisfied: pandas in /databricks/python3/lib/python3.11/site-packages (from dbdemos) (1.5.3)\nRequirement already satisfied: databricks-sdk>=0.38.0 in /databricks/python3/lib/python3.11/site-packages (from dbdemos) (0.40.0)\nRequirement already satisfied: google-auth~=2.0 in /databricks/python3/lib/python3.11/site-packages (from databricks-sdk>=0.38.0->dbdemos) (2.35.0)\nRequirement already satisfied: charset-normalizer<4,>=2 in /databricks/python3/lib/python3.11/site-packages (from requests->dbdemos) (2.0.4)\nRequirement already satisfied: idna<4,>=2.5 in /databricks/python3/lib/python3.11/site-packages (from requests->dbdemos) (3.4)\nRequirement already satisfied: urllib3<3,>=1.21.1 in /databricks/python3/lib/python3.11/site-packages (from requests->dbdemos) (1.26.16)\nRequirement already satisfied: certifi>=2017.4.17 in /databricks/python3/lib/python3.11/site-packages (from requests->dbdemos) (2023.7.22)\nRequirement already satisfied: python-dateutil>=2.8.1 in /databricks/python3/lib/python3.11/site-packages (from pandas->dbdemos) (2.8.2)\nRequirement already satisfied: pytz>=2020.1 in /databricks/python3/lib/python3.11/site-packages (from pandas->dbdemos) (2022.7)\nRequirement already satisfied: numpy>=1.21.0 in /databricks/python3/lib/python3.11/site-packages (from pandas->dbdemos) (1.23.5)\nRequirement already satisfied: cachetools<6.0,>=2.0.0 in /databricks/python3/lib/python3.11/site-packages (from google-auth~=2.0->databricks-sdk>=0.38.0->dbdemos) (5.5.0)\nRequirement already satisfied: pyasn1-modules>=0.2.1 in /databricks/python3/lib/python3.11/site-packages (from google-auth~=2.0->databricks-sdk>=0.38.0->dbdemos) (0.2.8)\nRequirement already satisfied: rsa<5,>=3.1.4 in /databricks/python3/lib/python3.11/site-packages (from google-auth~=2.0->databricks-sdk>=0.38.0->dbdemos) (4.9)\nRequirement already satisfied: six>=1.5 in /usr/lib/python3/dist-packages (from python-dateutil>=2.8.1->pandas->dbdemos) (1.16.0)\nRequirement already satisfied: pyasn1<0.5.0,>=0.4.6 in /databricks/python3/lib/python3.11/site-packages (from pyasn1-modules>=0.2.1->google-auth~=2.0->databricks-sdk>=0.38.0->dbdemos) (0.4.8)\n\u001B[43mNote: you may need to restart the kernel using %restart_python or dbutils.library.restartPython() to use updated packages.\u001B[0m\n"
     ]
    }
   ],
   "source": [
    "%pip install dbdemos"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "e30cd910-8e7a-4a5d-a242-18e11f978174",
     "showTitle": false,
     "tableResultSettingsMap": {},
     "title": ""
    }
   },
   "outputs": [],
   "source": [
    "%restart_python\n",
    "dbutils.library.restartPython()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "12c8e527-3425-48d0-ad5f-4232e6aa22cb",
     "showTitle": false,
     "tableResultSettingsMap": {},
     "title": ""
    }
   },
   "outputs": [
    {
     "output_type": "stream",
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Installing demo llm-tools-functions under /Users/odl_user_1663962@databrickslabs.com, please wait...\nHelp us improving dbdemos, share your feedback or create an issue if something isn't working: https://github.com/databricks-demos/dbdemos\n"
     ]
    },
    {
     "output_type": "display_data",
     "data": {
      "text/html": [
       "\n",
       "    <style>\n",
       "    .dbdemos_install{\n",
       "                        font-family: -apple-system,BlinkMacSystemFont,Segoe UI,Roboto,Helvetica Neue,Arial,Noto Sans,sans-serif,Apple Color Emoji,Segoe UI Emoji,Segoe UI Symbol,Noto Color Emoji,FontAwesome;\n",
       "    color: #3b3b3b;\n",
       "    box-shadow: 0 .15rem 1.15rem 0 rgba(58,59,69,.15)!important;\n",
       "    padding: 10px 20px 20px 20px;\n",
       "    margin: 10px;\n",
       "    }\n",
       "    .dbdemos_block{\n",
       "        display: block !important;\n",
       "    }\n",
       "     .update_container {\n",
       "        display: flex;\n",
       "        gap: 20px;\n",
       "        padding: 10px;\n",
       "        margin: 10px 0;\n",
       "    }\n",
       "    .update_box {\n",
       "        flex: 1;\n",
       "        background-color: #f3fff9;\n",
       "        padding: 15px;\n",
       "        border-radius: 5px;\n",
       "        box-shadow: 0 .15rem 1.15rem 0 rgba(58, 59, 69, .15);\n",
       "        overflow: hidden;\n",
       "    }\n",
       "    .update_title {\n",
       "        font-weight: bold;\n",
       "        color: #34a853;\n",
       "        margin-bottom: 10px;\n",
       "        font-size: 1.4em;\n",
       "    }\n",
       "    .code {\n",
       "        padding: 5px;\n",
       "        border: 1px solid #e4e4e4;\n",
       "        font-family: monospace;\n",
       "        background-color: #f5f5f5;\n",
       "        margin: 5px 0px 0px 0px;\n",
       "        display: inline;\n",
       "    }\n",
       "    .update_image {\n",
       "        float: right;\n",
       "        width: 200px;\n",
       "        margin: 0 0 10px 10px;\n",
       "        border-radius: 5px;\n",
       "    }\n",
       "    .subfolder {\n",
       "        padding-left: 30px;\n",
       "    }\n",
       "    .notebook {\n",
       "        margin-bottom: 3px;\n",
       "    }\n",
       "    .dbdemos_install a {\n",
       "        color: #3835a4;\n",
       "    }\n",
       "    .container_dbdemos {\n",
       "        padding-left: 20px;\n",
       "    }\n",
       "    .path_desc {\n",
       "        color: #928e9b;\n",
       "        font-style: oblique;\n",
       "    }\n",
       "    </style>\n",
       "                        <div class=\"dbdemos_install\"><h2 style=\"color: #4875c2\">Installation in progress...</h2>\n",
       "                            \n",
       "        <div class=\"update_container\">\n",
       "            <div class=\"update_box\">\n",
       "                <img src=\"https://github.com/databricks-demos/dbdemos-resources/raw/main/icon/llm-tools-functions.jpg\" class=\"update_image\">\n",
       "                <div class=\"update_title\">Discover our New GenAI demo!</div>\n",
       "                <p>Learn how Databricks makes it easy to create powerful, intelligent AI agents to augment your GenAI applications:<br><br>\n",
       "    <span class=\"code\">dbdemos.install('llm-tools-functions')</span>\n",
       "    </p>\n",
       "            </div>\n",
       "            <div class=\"update_box\">\n",
       "                <img src=\"https://github.com/databricks-demos/dbdemos-resources/raw/main/icon/aibi-marketing-campaign.jpg\" class=\"update_image\">\n",
       "                <div class=\"update_title\">Try AI/BI: Dashboard & Genie demos</div>\n",
       "                <p>Discover how Databricks simplifies data analysis by allowing teams to understand their data both visually and in natural language</p>\n",
       "                <p>Find all our AI/BI demo: <span class=\"code\">dbdemos.list_demos()</span></p>\n",
       "            </div>\n",
       "        </div>\n",
       "        This demo content will be installed in the schema `main`.`dbdemos_agent_tools`<br/>\n",
       "                        </div>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "output_type": "display_data",
     "data": {
      "text/html": [
       "\n",
       "    <style>\n",
       "    .dbdemos_install{\n",
       "                        font-family: -apple-system,BlinkMacSystemFont,Segoe UI,Roboto,Helvetica Neue,Arial,Noto Sans,sans-serif,Apple Color Emoji,Segoe UI Emoji,Segoe UI Symbol,Noto Color Emoji,FontAwesome;\n",
       "    color: #3b3b3b;\n",
       "    box-shadow: 0 .15rem 1.15rem 0 rgba(58,59,69,.15)!important;\n",
       "    padding: 10px 20px 20px 20px;\n",
       "    margin: 10px;\n",
       "    }\n",
       "    .dbdemos_block{\n",
       "        display: block !important;\n",
       "    }\n",
       "     .update_container {\n",
       "        display: flex;\n",
       "        gap: 20px;\n",
       "        padding: 10px;\n",
       "        margin: 10px 0;\n",
       "    }\n",
       "    .update_box {\n",
       "        flex: 1;\n",
       "        background-color: #f3fff9;\n",
       "        padding: 15px;\n",
       "        border-radius: 5px;\n",
       "        box-shadow: 0 .15rem 1.15rem 0 rgba(58, 59, 69, .15);\n",
       "        overflow: hidden;\n",
       "    }\n",
       "    .update_title {\n",
       "        font-weight: bold;\n",
       "        color: #34a853;\n",
       "        margin-bottom: 10px;\n",
       "        font-size: 1.4em;\n",
       "    }\n",
       "    .code {\n",
       "        padding: 5px;\n",
       "        border: 1px solid #e4e4e4;\n",
       "        font-family: monospace;\n",
       "        background-color: #f5f5f5;\n",
       "        margin: 5px 0px 0px 0px;\n",
       "        display: inline;\n",
       "    }\n",
       "    .update_image {\n",
       "        float: right;\n",
       "        width: 200px;\n",
       "        margin: 0 0 10px 10px;\n",
       "        border-radius: 5px;\n",
       "    }\n",
       "    .subfolder {\n",
       "        padding-left: 30px;\n",
       "    }\n",
       "    .notebook {\n",
       "        margin-bottom: 3px;\n",
       "    }\n",
       "    .dbdemos_install a {\n",
       "        color: #3835a4;\n",
       "    }\n",
       "    .container_dbdemos {\n",
       "        padding-left: 20px;\n",
       "    }\n",
       "    .path_desc {\n",
       "        color: #928e9b;\n",
       "        font-style: oblique;\n",
       "    }\n",
       "    </style><div class=\"dbdemos_install\">\n",
       "                      <h1 style=\"color: #eb0707\">Installation error: Folder /Users/odl_user_1663962@databrickslabs.com/llm-tools-functions isn't empty.</h1> \n",
       "                        Please install demo with overwrite=True to replace the existing folder content under /Users/odl_user_1663962@databrickslabs.com/llm-tools-functions:\n",
       "                                         <div class=\"code dbdemos_block\">dbdemos.install('llm-tools-functions', overwrite=True, path='/Users/odl_user_1663962@databrickslabs.com/llm-tools-functions')</div><br/>\n",
       "                                         All content under /Users/odl_user_1663962@databrickslabs.com/llm-tools-functions will be deleted.<br/><br/>\n",
       "                                         <strong>Details</strong><br/>\n",
       "                                         Folder list response: <div class=\"code dbdemos_block\">{\"object_type\": \"DIRECTORY\", \"path\": \"/Users/odl_user_1663962@databrickslabs.com/llm-tools-functions\", \"object_id\": 2062702287672120, \"resource_id\": \"2062702287672120\"}</div>\n",
       "                      </div>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "output_type": "display_data",
     "data": {
      "text/plain": [
       "\u001B[0;31m---------------------------------------------------------------------------\u001B[0m\n",
       "\u001B[0;31mExistingResourceException\u001B[0m                 Traceback (most recent call last)\n",
       "File \u001B[0;32m<command-5373698456273971>, line 2\u001B[0m\n",
       "\u001B[1;32m      1\u001B[0m \u001B[38;5;28;01mimport\u001B[39;00m \u001B[38;5;21;01mdbdemos\u001B[39;00m\n",
       "\u001B[0;32m----> 2\u001B[0m dbdemos\u001B[38;5;241m.\u001B[39minstall(\u001B[38;5;124m'\u001B[39m\u001B[38;5;124mllm-tools-functions\u001B[39m\u001B[38;5;124m'\u001B[39m, catalog\u001B[38;5;241m=\u001B[39m\u001B[38;5;124m'\u001B[39m\u001B[38;5;124mmain\u001B[39m\u001B[38;5;124m'\u001B[39m, schema\u001B[38;5;241m=\u001B[39m\u001B[38;5;124m'\u001B[39m\u001B[38;5;124mdbdemos_agent_tools\u001B[39m\u001B[38;5;124m'\u001B[39m)\n",
       "\n",
       "File \u001B[0;32m/local_disk0/.ephemeral_nfs/envs/pythonEnv-0d2a3b85-99ec-42fc-ab7b-cd12f20dadd4/lib/python3.11/site-packages/dbdemos/dbdemos.py:245\u001B[0m, in \u001B[0;36minstall\u001B[0;34m(demo_name, path, overwrite, username, pat_token, workspace_url, skip_dashboards, cloud, start_cluster, use_current_cluster, current_cluster_id, warehouse_name, debug, catalog, schema, serverless, skip_genie_rooms, create_schema)\u001B[0m\n",
       "\u001B[1;32m    242\u001B[0m \u001B[38;5;28;01mif\u001B[39;00m \u001B[38;5;129;01mnot\u001B[39;00m installer\u001B[38;5;241m.\u001B[39mtest_premium_pricing():\n",
       "\u001B[1;32m    243\u001B[0m     \u001B[38;5;66;03m#Force dashboard skip as dbsql isn't available to avoid any error.\u001B[39;00m\n",
       "\u001B[1;32m    244\u001B[0m     skip_dashboards \u001B[38;5;241m=\u001B[39m \u001B[38;5;28;01mTrue\u001B[39;00m\n",
       "\u001B[0;32m--> 245\u001B[0m installer\u001B[38;5;241m.\u001B[39minstall_demo(demo_name, path, overwrite, skip_dashboards \u001B[38;5;241m=\u001B[39m skip_dashboards, start_cluster \u001B[38;5;241m=\u001B[39m start_cluster, use_current_cluster \u001B[38;5;241m=\u001B[39m use_current_cluster,\n",
       "\u001B[1;32m    246\u001B[0m                        debug \u001B[38;5;241m=\u001B[39m debug, catalog \u001B[38;5;241m=\u001B[39m catalog, schema \u001B[38;5;241m=\u001B[39m schema, serverless \u001B[38;5;241m=\u001B[39m serverless, warehouse_name\u001B[38;5;241m=\u001B[39mwarehouse_name, skip_genie_rooms\u001B[38;5;241m=\u001B[39mskip_genie_rooms, create_schema\u001B[38;5;241m=\u001B[39mcreate_schema)\n",
       "\n",
       "File \u001B[0;32m/local_disk0/.ephemeral_nfs/envs/pythonEnv-0d2a3b85-99ec-42fc-ab7b-cd12f20dadd4/lib/python3.11/site-packages/dbdemos/installer.py:310\u001B[0m, in \u001B[0;36mInstaller.install_demo\u001B[0;34m(self, demo_name, install_path, overwrite, update_cluster_if_exists, skip_dashboards, start_cluster, use_current_cluster, debug, catalog, schema, serverless, warehouse_name, skip_genie_rooms, create_schema)\u001B[0m\n",
       "\u001B[1;32m    308\u001B[0m     \u001B[38;5;28mself\u001B[39m\u001B[38;5;241m.\u001B[39mreport\u001B[38;5;241m.\u001B[39mdisplay_cluster_creation_warn(e, demo_conf)\n",
       "\u001B[1;32m    309\u001B[0m     cluster_name \u001B[38;5;241m=\u001B[39m \u001B[38;5;124m\"\u001B[39m\u001B[38;5;124mCurrent Cluster\u001B[39m\u001B[38;5;124m\"\u001B[39m\n",
       "\u001B[0;32m--> 310\u001B[0m \u001B[38;5;28mself\u001B[39m\u001B[38;5;241m.\u001B[39mcheck_if_install_folder_exists(demo_name, install_path, demo_conf, overwrite, debug)\n",
       "\u001B[1;32m    311\u001B[0m pipeline_ids \u001B[38;5;241m=\u001B[39m \u001B[38;5;28mself\u001B[39m\u001B[38;5;241m.\u001B[39mload_demo_pipelines(demo_name, demo_conf, debug, serverless)\n",
       "\u001B[1;32m    312\u001B[0m dashboards \u001B[38;5;241m=\u001B[39m [] \u001B[38;5;28;01mif\u001B[39;00m skip_dashboards \u001B[38;5;28;01melse\u001B[39;00m \u001B[38;5;28mself\u001B[39m\u001B[38;5;241m.\u001B[39minstaller_dashboard\u001B[38;5;241m.\u001B[39minstall_dashboards(demo_conf, install_path, warehouse_name, debug)\n",
       "\n",
       "File \u001B[0;32m/local_disk0/.ephemeral_nfs/envs/pythonEnv-0d2a3b85-99ec-42fc-ab7b-cd12f20dadd4/lib/python3.11/site-packages/dbdemos/installer.py:403\u001B[0m, in \u001B[0;36mInstaller.check_if_install_folder_exists\u001B[0;34m(self, demo_name, install_path, demo_conf, overwrite, debug)\u001B[0m\n",
       "\u001B[1;32m    401\u001B[0m \u001B[38;5;28;01mif\u001B[39;00m \u001B[38;5;124m'\u001B[39m\u001B[38;5;124mobject_type\u001B[39m\u001B[38;5;124m'\u001B[39m \u001B[38;5;129;01min\u001B[39;00m s:\n",
       "\u001B[1;32m    402\u001B[0m     \u001B[38;5;28;01mif\u001B[39;00m \u001B[38;5;129;01mnot\u001B[39;00m overwrite:\n",
       "\u001B[0;32m--> 403\u001B[0m         \u001B[38;5;28mself\u001B[39m\u001B[38;5;241m.\u001B[39mreport\u001B[38;5;241m.\u001B[39mdisplay_folder_already_existing(ExistingResourceException(install_path, s), demo_conf)\n",
       "\u001B[1;32m    404\u001B[0m     \u001B[38;5;28;01mif\u001B[39;00m debug:\n",
       "\u001B[1;32m    405\u001B[0m         \u001B[38;5;28mprint\u001B[39m(\u001B[38;5;124mf\u001B[39m\u001B[38;5;124m\"\u001B[39m\u001B[38;5;124m    Folder \u001B[39m\u001B[38;5;132;01m{\u001B[39;00minstall_path\u001B[38;5;132;01m}\u001B[39;00m\u001B[38;5;124m already exists. Deleting the existing content...\u001B[39m\u001B[38;5;124m\"\u001B[39m)\n",
       "\n",
       "File \u001B[0;32m/local_disk0/.ephemeral_nfs/envs/pythonEnv-0d2a3b85-99ec-42fc-ab7b-cd12f20dadd4/lib/python3.11/site-packages/dbdemos/installer_report.py:140\u001B[0m, in \u001B[0;36mInstallerReport.display_folder_already_existing\u001B[0;34m(self, exception, demo_conf)\u001B[0m\n",
       "\u001B[1;32m    139\u001B[0m \u001B[38;5;28;01mdef\u001B[39;00m \u001B[38;5;21mdisplay_folder_already_existing\u001B[39m(\u001B[38;5;28mself\u001B[39m, exception: ExistingResourceException, demo_conf: DemoConf):\n",
       "\u001B[0;32m--> 140\u001B[0m     \u001B[38;5;28mself\u001B[39m\u001B[38;5;241m.\u001B[39mdisplay_error(exception, \u001B[38;5;124mf\u001B[39m\u001B[38;5;124m\"\"\"\u001B[39m\u001B[38;5;124mPlease install demo with overwrite=True to replace the existing folder content under \u001B[39m\u001B[38;5;132;01m{\u001B[39;00mexception\u001B[38;5;241m.\u001B[39minstall_path\u001B[38;5;132;01m}\u001B[39;00m\u001B[38;5;124m:\u001B[39m\n",
       "\u001B[1;32m    141\u001B[0m \u001B[38;5;124m                                     <div class=\u001B[39m\u001B[38;5;124m\"\u001B[39m\u001B[38;5;124mcode dbdemos_block\u001B[39m\u001B[38;5;124m\"\u001B[39m\u001B[38;5;124m>dbdemos.install(\u001B[39m\u001B[38;5;124m'\u001B[39m\u001B[38;5;132;01m{\u001B[39;00mdemo_conf\u001B[38;5;241m.\u001B[39mname\u001B[38;5;132;01m}\u001B[39;00m\u001B[38;5;124m'\u001B[39m\u001B[38;5;124m, overwrite=True, path=\u001B[39m\u001B[38;5;124m'\u001B[39m\u001B[38;5;132;01m{\u001B[39;00mexception\u001B[38;5;241m.\u001B[39minstall_path\u001B[38;5;132;01m}\u001B[39;00m\u001B[38;5;124m'\u001B[39m\u001B[38;5;124m)</div><br/>\u001B[39m\n",
       "\u001B[1;32m    142\u001B[0m \u001B[38;5;124m                                     All content under \u001B[39m\u001B[38;5;132;01m{\u001B[39;00mexception\u001B[38;5;241m.\u001B[39minstall_path\u001B[38;5;132;01m}\u001B[39;00m\u001B[38;5;124m will be deleted.<br/><br/>\u001B[39m\n",
       "\u001B[1;32m    143\u001B[0m \u001B[38;5;124m                                     <strong>Details</strong><br/>\u001B[39m\n",
       "\u001B[1;32m    144\u001B[0m \u001B[38;5;124m                                     Folder list response: <div class=\u001B[39m\u001B[38;5;124m\"\u001B[39m\u001B[38;5;124mcode dbdemos_block\u001B[39m\u001B[38;5;124m\"\u001B[39m\u001B[38;5;124m>\u001B[39m\u001B[38;5;132;01m{\u001B[39;00mjson\u001B[38;5;241m.\u001B[39mdumps(exception\u001B[38;5;241m.\u001B[39mresponse)\u001B[38;5;132;01m}\u001B[39;00m\u001B[38;5;124m</div>\u001B[39m\u001B[38;5;124m\"\"\"\u001B[39m)\n",
       "\n",
       "File \u001B[0;32m/local_disk0/.ephemeral_nfs/envs/pythonEnv-0d2a3b85-99ec-42fc-ab7b-cd12f20dadd4/lib/python3.11/site-packages/dbdemos/installer_report.py:221\u001B[0m, in \u001B[0;36mInstallerReport.display_error\u001B[0;34m(self, exception, message, raise_error, warning)\u001B[0m\n",
       "\u001B[1;32m    219\u001B[0m     \u001B[38;5;28mprint\u001B[39m(error)\n",
       "\u001B[1;32m    220\u001B[0m \u001B[38;5;28;01mif\u001B[39;00m raise_error:\n",
       "\u001B[0;32m--> 221\u001B[0m     \u001B[38;5;28;01mraise\u001B[39;00m exception\n",
       "\n",
       "\u001B[0;31mExistingResourceException\u001B[0m: Folder /Users/odl_user_1663962@databrickslabs.com/llm-tools-functions isn't empty."
      ]
     },
     "metadata": {
      "application/vnd.databricks.v1+output": {
       "addedWidgets": {},
       "arguments": {},
       "datasetInfos": [],
       "jupyterProps": {
        "ename": "ExistingResourceException",
        "evalue": "Folder /Users/odl_user_1663962@databrickslabs.com/llm-tools-functions isn't empty."
       },
       "metadata": {
        "errorSummary": "<span class='ansi-red-fg'>ExistingResourceException</span>: Folder /Users/odl_user_1663962@databrickslabs.com/llm-tools-functions isn't empty."
       },
       "removedWidgets": [],
       "sqlProps": null,
       "stackFrames": [
        "\u001B[0;31m---------------------------------------------------------------------------\u001B[0m",
        "\u001B[0;31mExistingResourceException\u001B[0m                 Traceback (most recent call last)",
        "File \u001B[0;32m<command-5373698456273971>, line 2\u001B[0m\n\u001B[1;32m      1\u001B[0m \u001B[38;5;28;01mimport\u001B[39;00m \u001B[38;5;21;01mdbdemos\u001B[39;00m\n\u001B[0;32m----> 2\u001B[0m dbdemos\u001B[38;5;241m.\u001B[39minstall(\u001B[38;5;124m'\u001B[39m\u001B[38;5;124mllm-tools-functions\u001B[39m\u001B[38;5;124m'\u001B[39m, catalog\u001B[38;5;241m=\u001B[39m\u001B[38;5;124m'\u001B[39m\u001B[38;5;124mmain\u001B[39m\u001B[38;5;124m'\u001B[39m, schema\u001B[38;5;241m=\u001B[39m\u001B[38;5;124m'\u001B[39m\u001B[38;5;124mdbdemos_agent_tools\u001B[39m\u001B[38;5;124m'\u001B[39m)\n",
        "File \u001B[0;32m/local_disk0/.ephemeral_nfs/envs/pythonEnv-0d2a3b85-99ec-42fc-ab7b-cd12f20dadd4/lib/python3.11/site-packages/dbdemos/dbdemos.py:245\u001B[0m, in \u001B[0;36minstall\u001B[0;34m(demo_name, path, overwrite, username, pat_token, workspace_url, skip_dashboards, cloud, start_cluster, use_current_cluster, current_cluster_id, warehouse_name, debug, catalog, schema, serverless, skip_genie_rooms, create_schema)\u001B[0m\n\u001B[1;32m    242\u001B[0m \u001B[38;5;28;01mif\u001B[39;00m \u001B[38;5;129;01mnot\u001B[39;00m installer\u001B[38;5;241m.\u001B[39mtest_premium_pricing():\n\u001B[1;32m    243\u001B[0m     \u001B[38;5;66;03m#Force dashboard skip as dbsql isn't available to avoid any error.\u001B[39;00m\n\u001B[1;32m    244\u001B[0m     skip_dashboards \u001B[38;5;241m=\u001B[39m \u001B[38;5;28;01mTrue\u001B[39;00m\n\u001B[0;32m--> 245\u001B[0m installer\u001B[38;5;241m.\u001B[39minstall_demo(demo_name, path, overwrite, skip_dashboards \u001B[38;5;241m=\u001B[39m skip_dashboards, start_cluster \u001B[38;5;241m=\u001B[39m start_cluster, use_current_cluster \u001B[38;5;241m=\u001B[39m use_current_cluster,\n\u001B[1;32m    246\u001B[0m                        debug \u001B[38;5;241m=\u001B[39m debug, catalog \u001B[38;5;241m=\u001B[39m catalog, schema \u001B[38;5;241m=\u001B[39m schema, serverless \u001B[38;5;241m=\u001B[39m serverless, warehouse_name\u001B[38;5;241m=\u001B[39mwarehouse_name, skip_genie_rooms\u001B[38;5;241m=\u001B[39mskip_genie_rooms, create_schema\u001B[38;5;241m=\u001B[39mcreate_schema)\n",
        "File \u001B[0;32m/local_disk0/.ephemeral_nfs/envs/pythonEnv-0d2a3b85-99ec-42fc-ab7b-cd12f20dadd4/lib/python3.11/site-packages/dbdemos/installer.py:310\u001B[0m, in \u001B[0;36mInstaller.install_demo\u001B[0;34m(self, demo_name, install_path, overwrite, update_cluster_if_exists, skip_dashboards, start_cluster, use_current_cluster, debug, catalog, schema, serverless, warehouse_name, skip_genie_rooms, create_schema)\u001B[0m\n\u001B[1;32m    308\u001B[0m     \u001B[38;5;28mself\u001B[39m\u001B[38;5;241m.\u001B[39mreport\u001B[38;5;241m.\u001B[39mdisplay_cluster_creation_warn(e, demo_conf)\n\u001B[1;32m    309\u001B[0m     cluster_name \u001B[38;5;241m=\u001B[39m \u001B[38;5;124m\"\u001B[39m\u001B[38;5;124mCurrent Cluster\u001B[39m\u001B[38;5;124m\"\u001B[39m\n\u001B[0;32m--> 310\u001B[0m \u001B[38;5;28mself\u001B[39m\u001B[38;5;241m.\u001B[39mcheck_if_install_folder_exists(demo_name, install_path, demo_conf, overwrite, debug)\n\u001B[1;32m    311\u001B[0m pipeline_ids \u001B[38;5;241m=\u001B[39m \u001B[38;5;28mself\u001B[39m\u001B[38;5;241m.\u001B[39mload_demo_pipelines(demo_name, demo_conf, debug, serverless)\n\u001B[1;32m    312\u001B[0m dashboards \u001B[38;5;241m=\u001B[39m [] \u001B[38;5;28;01mif\u001B[39;00m skip_dashboards \u001B[38;5;28;01melse\u001B[39;00m \u001B[38;5;28mself\u001B[39m\u001B[38;5;241m.\u001B[39minstaller_dashboard\u001B[38;5;241m.\u001B[39minstall_dashboards(demo_conf, install_path, warehouse_name, debug)\n",
        "File \u001B[0;32m/local_disk0/.ephemeral_nfs/envs/pythonEnv-0d2a3b85-99ec-42fc-ab7b-cd12f20dadd4/lib/python3.11/site-packages/dbdemos/installer.py:403\u001B[0m, in \u001B[0;36mInstaller.check_if_install_folder_exists\u001B[0;34m(self, demo_name, install_path, demo_conf, overwrite, debug)\u001B[0m\n\u001B[1;32m    401\u001B[0m \u001B[38;5;28;01mif\u001B[39;00m \u001B[38;5;124m'\u001B[39m\u001B[38;5;124mobject_type\u001B[39m\u001B[38;5;124m'\u001B[39m \u001B[38;5;129;01min\u001B[39;00m s:\n\u001B[1;32m    402\u001B[0m     \u001B[38;5;28;01mif\u001B[39;00m \u001B[38;5;129;01mnot\u001B[39;00m overwrite:\n\u001B[0;32m--> 403\u001B[0m         \u001B[38;5;28mself\u001B[39m\u001B[38;5;241m.\u001B[39mreport\u001B[38;5;241m.\u001B[39mdisplay_folder_already_existing(ExistingResourceException(install_path, s), demo_conf)\n\u001B[1;32m    404\u001B[0m     \u001B[38;5;28;01mif\u001B[39;00m debug:\n\u001B[1;32m    405\u001B[0m         \u001B[38;5;28mprint\u001B[39m(\u001B[38;5;124mf\u001B[39m\u001B[38;5;124m\"\u001B[39m\u001B[38;5;124m    Folder \u001B[39m\u001B[38;5;132;01m{\u001B[39;00minstall_path\u001B[38;5;132;01m}\u001B[39;00m\u001B[38;5;124m already exists. Deleting the existing content...\u001B[39m\u001B[38;5;124m\"\u001B[39m)\n",
        "File \u001B[0;32m/local_disk0/.ephemeral_nfs/envs/pythonEnv-0d2a3b85-99ec-42fc-ab7b-cd12f20dadd4/lib/python3.11/site-packages/dbdemos/installer_report.py:140\u001B[0m, in \u001B[0;36mInstallerReport.display_folder_already_existing\u001B[0;34m(self, exception, demo_conf)\u001B[0m\n\u001B[1;32m    139\u001B[0m \u001B[38;5;28;01mdef\u001B[39;00m \u001B[38;5;21mdisplay_folder_already_existing\u001B[39m(\u001B[38;5;28mself\u001B[39m, exception: ExistingResourceException, demo_conf: DemoConf):\n\u001B[0;32m--> 140\u001B[0m     \u001B[38;5;28mself\u001B[39m\u001B[38;5;241m.\u001B[39mdisplay_error(exception, \u001B[38;5;124mf\u001B[39m\u001B[38;5;124m\"\"\"\u001B[39m\u001B[38;5;124mPlease install demo with overwrite=True to replace the existing folder content under \u001B[39m\u001B[38;5;132;01m{\u001B[39;00mexception\u001B[38;5;241m.\u001B[39minstall_path\u001B[38;5;132;01m}\u001B[39;00m\u001B[38;5;124m:\u001B[39m\n\u001B[1;32m    141\u001B[0m \u001B[38;5;124m                                     <div class=\u001B[39m\u001B[38;5;124m\"\u001B[39m\u001B[38;5;124mcode dbdemos_block\u001B[39m\u001B[38;5;124m\"\u001B[39m\u001B[38;5;124m>dbdemos.install(\u001B[39m\u001B[38;5;124m'\u001B[39m\u001B[38;5;132;01m{\u001B[39;00mdemo_conf\u001B[38;5;241m.\u001B[39mname\u001B[38;5;132;01m}\u001B[39;00m\u001B[38;5;124m'\u001B[39m\u001B[38;5;124m, overwrite=True, path=\u001B[39m\u001B[38;5;124m'\u001B[39m\u001B[38;5;132;01m{\u001B[39;00mexception\u001B[38;5;241m.\u001B[39minstall_path\u001B[38;5;132;01m}\u001B[39;00m\u001B[38;5;124m'\u001B[39m\u001B[38;5;124m)</div><br/>\u001B[39m\n\u001B[1;32m    142\u001B[0m \u001B[38;5;124m                                     All content under \u001B[39m\u001B[38;5;132;01m{\u001B[39;00mexception\u001B[38;5;241m.\u001B[39minstall_path\u001B[38;5;132;01m}\u001B[39;00m\u001B[38;5;124m will be deleted.<br/><br/>\u001B[39m\n\u001B[1;32m    143\u001B[0m \u001B[38;5;124m                                     <strong>Details</strong><br/>\u001B[39m\n\u001B[1;32m    144\u001B[0m \u001B[38;5;124m                                     Folder list response: <div class=\u001B[39m\u001B[38;5;124m\"\u001B[39m\u001B[38;5;124mcode dbdemos_block\u001B[39m\u001B[38;5;124m\"\u001B[39m\u001B[38;5;124m>\u001B[39m\u001B[38;5;132;01m{\u001B[39;00mjson\u001B[38;5;241m.\u001B[39mdumps(exception\u001B[38;5;241m.\u001B[39mresponse)\u001B[38;5;132;01m}\u001B[39;00m\u001B[38;5;124m</div>\u001B[39m\u001B[38;5;124m\"\"\"\u001B[39m)\n",
        "File \u001B[0;32m/local_disk0/.ephemeral_nfs/envs/pythonEnv-0d2a3b85-99ec-42fc-ab7b-cd12f20dadd4/lib/python3.11/site-packages/dbdemos/installer_report.py:221\u001B[0m, in \u001B[0;36mInstallerReport.display_error\u001B[0;34m(self, exception, message, raise_error, warning)\u001B[0m\n\u001B[1;32m    219\u001B[0m     \u001B[38;5;28mprint\u001B[39m(error)\n\u001B[1;32m    220\u001B[0m \u001B[38;5;28;01mif\u001B[39;00m raise_error:\n\u001B[0;32m--> 221\u001B[0m     \u001B[38;5;28;01mraise\u001B[39;00m exception\n",
        "\u001B[0;31mExistingResourceException\u001B[0m: Folder /Users/odl_user_1663962@databrickslabs.com/llm-tools-functions isn't empty."
       ],
       "type": "baseError"
      }
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "import dbdemos\n",
    "dbdemos.install('llm-tools-functions', catalog='main', schema='dbdemos_agent_tools')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "implicitDf": true,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "557684a8-00c5-4b71-9ebb-7477a331e01a",
     "showTitle": false,
     "tableResultSettingsMap": {},
     "title": ""
    }
   },
   "outputs": [
    {
     "output_type": "display_data",
     "data": {
      "text/html": [
       "<style scoped>\n",
       "  .table-result-container {\n",
       "    max-height: 300px;\n",
       "    overflow: auto;\n",
       "  }\n",
       "  table, th, td {\n",
       "    border: 1px solid black;\n",
       "    border-collapse: collapse;\n",
       "  }\n",
       "  th, td {\n",
       "    padding: 5px;\n",
       "  }\n",
       "  th {\n",
       "    text-align: left;\n",
       "  }\n",
       "</style><div class='table-result-container'><table class='table-result'><thead style='background-color: white'><tr><th>COUNT(*)</th></tr></thead><tbody><tr><td>123849</td></tr></tbody></table></div>"
      ]
     },
     "metadata": {
      "application/vnd.databricks.v1+output": {
       "addedWidgets": {},
       "aggData": [],
       "aggError": "",
       "aggOverflow": false,
       "aggSchema": [],
       "aggSeriesLimitReached": false,
       "aggType": "",
       "arguments": {},
       "columnCustomDisplayInfos": {},
       "data": [
        [
         123849
        ]
       ],
       "datasetInfos": [
        {
         "name": "_sqldf",
         "schema": {
          "fields": [
           {
            "metadata": {},
            "name": "COUNT(*)",
            "nullable": false,
            "type": "long"
           }
          ],
          "type": "struct"
         },
         "tableIdentifier": null,
         "typeStr": "pyspark.sql.connect.dataframe.DataFrame"
        }
       ],
       "dbfsResultPath": null,
       "isJsonSchema": true,
       "metadata": {
        "createTempViewForImplicitDf": true,
        "dataframeName": "_sqldf",
        "executionCount": 3
       },
       "overflow": false,
       "plotOptions": {
        "customPlotOptions": {},
        "displayType": "table",
        "pivotAggregation": null,
        "pivotColumns": null,
        "xColumns": null,
        "yColumns": null
       },
       "removedWidgets": [],
       "schema": [
        {
         "metadata": "{}",
         "name": "COUNT(*)",
         "type": "\"long\""
        }
       ],
       "type": "table"
      }
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "%sql\n",
    "SELECT COUNT(*) FROM main.default.postings2;"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "implicitDf": true,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "6038d4f4-148d-4fd2-8333-4f5f36674e4c",
     "showTitle": false,
     "tableResultSettingsMap": {},
     "title": ""
    }
   },
   "outputs": [
    {
     "output_type": "display_data",
     "data": {
      "text/html": [
       "<style scoped>\n",
       "  .table-result-container {\n",
       "    max-height: 300px;\n",
       "    overflow: auto;\n",
       "  }\n",
       "  table, th, td {\n",
       "    border: 1px solid black;\n",
       "    border-collapse: collapse;\n",
       "  }\n",
       "  th, td {\n",
       "    padding: 5px;\n",
       "  }\n",
       "  th {\n",
       "    text-align: left;\n",
       "  }\n",
       "</style><div class='table-result-container'><table class='table-result'><thead style='background-color: white'><tr><th>job_id</th><th>company_name</th><th>title</th><th>description</th><th>max_salary</th><th>pay_period</th><th>location</th><th>company_id</th><th>views</th><th>med_salary</th><th>min_salary</th><th>formatted_work_type</th><th>applies</th><th>original_listed_time</th><th>remote_allowed</th><th>job_posting_url</th><th>application_url</th><th>application_type</th><th>expiry</th><th>closed_time</th><th>formatted_experience_level</th><th>skills_desc</th><th>listed_time</th><th>posting_domain</th><th>sponsored</th><th>work_type</th><th>currency</th><th>compensation_type</th><th>normalized_salary</th><th>zip_code</th><th>fips</th></tr></thead><tbody><tr><td>921716</td><td>Corcoran Sawyer Smith</td><td>Marketing Coordinator</td><td>Job descriptionA leading real estate firm in New Jersey is seeking an administrative Marketing Coordinator with some experience in graphic design. You will be working closely with our fun, kind, ambitious members of the sales team and our dynamic executive team on a daily basis. This is an opportunity to be part of a fast-growing, highly respected real estate brokerage with a reputation for exceptional marketing and extraordinary culture of cooperation and inclusion.Who you are:You must be a well-organized, creative, proactive, positive, and most importantly, kind-hearted person. Please, be responsible, respectful, and cool-under-pressure. Please, be proficient in Adobe Creative Cloud (Indesign, Illustrator, Photoshop) and Microsoft Office Suite. Above all, have fantastic taste and be a good-hearted, fun-loving person who loves working with people and is eager to learn.Role:Our office is a fast-paced environment. You’ll work directly with a Marketing team and communicate daily with other core staff and our large team of agents. This description is a brief overview, but your skills and interests will be considered in what you work on and as the role evolves over time.Agent Assistance- Receive & Organize Marketing Requests from Agents- Track Tasks & Communicate with Marketing team & Agents on Status- Prepare print materials and signs for open houses- Submit Orders to Printers & Communicate & Track DeadlinesGraphic Design & Branding- Managing brand strategy and messaging through website, social media, videos, online advertising, print placement and events- Receive, organize, and prioritize marketing requests from agents- Fulfill agent design requests including postcards, signs, email marketing and property brochures using pre-existing templates and creating custom designs- Maintain brand assets and generic filesEvents & Community- Plan and execute events and promotions- Manage Contacts & Vendors for Event Planning & SponsorshipsOur company is committed to creating a diverse environment and is proud to be an equal opportunity employer. All qualified applicants will receive consideration for employment without regard to race, color, religion, gender, gender identity or expression, sexual orientation, national origin, genetics, disability, age, or veteran status.Job Type: Full-time\n",
       "Pay: $18-20/hour\n",
       "Expected hours: 35 – 45 per week\n",
       "Benefits:Paid time offSchedule:8 hour shiftMonday to FridayExperience:Marketing: 1 year (Preferred)Graphic design: 2 years (Preferred)Work Location: In person\n",
       "</td><td>20.0</td><td>HOURLY</td><td>Princeton, NJ</td><td>2774458.0</td><td>20.0</td><td>null</td><td>17.0</td><td>Full-time</td><td>2.0</td><td>1.713397508E12</td><td>null</td><td>https://www.linkedin.com/jobs/view/921716/?trk=jobs_biz_prem_srch</td><td>null</td><td>ComplexOnsiteApply</td><td>1.715989508E12</td><td>null</td><td>null</td><td>Requirements: \n",
       "\n",
       "We are seeking a College or Graduate Student (can also be completed with school) with a focus in Planning, Architecture, Real Estate Development or Management or General Business. Must be able to work in an extremely fast paced environment and able to multitask and prioritize.</td><td>1.713397508E12</td><td>null</td><td>0</td><td>FULL_TIME</td><td>USD</td><td>BASE_SALARY</td><td>38480.0</td><td>8540</td><td>34021</td></tr></tbody></table></div>"
      ]
     },
     "metadata": {
      "application/vnd.databricks.v1+output": {
       "addedWidgets": {},
       "aggData": [],
       "aggError": "",
       "aggOverflow": false,
       "aggSchema": [],
       "aggSeriesLimitReached": false,
       "aggType": "",
       "arguments": {},
       "columnCustomDisplayInfos": {},
       "data": [
        [
         921716,
         "Corcoran Sawyer Smith",
         "Marketing Coordinator",
         "Job descriptionA leading real estate firm in New Jersey is seeking an administrative Marketing Coordinator with some experience in graphic design. You will be working closely with our fun, kind, ambitious members of the sales team and our dynamic executive team on a daily basis. This is an opportunity to be part of a fast-growing, highly respected real estate brokerage with a reputation for exceptional marketing and extraordinary culture of cooperation and inclusion.Who you are:You must be a well-organized, creative, proactive, positive, and most importantly, kind-hearted person. Please, be responsible, respectful, and cool-under-pressure. Please, be proficient in Adobe Creative Cloud (Indesign, Illustrator, Photoshop) and Microsoft Office Suite. Above all, have fantastic taste and be a good-hearted, fun-loving person who loves working with people and is eager to learn.Role:Our office is a fast-paced environment. You’ll work directly with a Marketing team and communicate daily with other core staff and our large team of agents. This description is a brief overview, but your skills and interests will be considered in what you work on and as the role evolves over time.Agent Assistance- Receive & Organize Marketing Requests from Agents- Track Tasks & Communicate with Marketing team & Agents on Status- Prepare print materials and signs for open houses- Submit Orders to Printers & Communicate & Track DeadlinesGraphic Design & Branding- Managing brand strategy and messaging through website, social media, videos, online advertising, print placement and events- Receive, organize, and prioritize marketing requests from agents- Fulfill agent design requests including postcards, signs, email marketing and property brochures using pre-existing templates and creating custom designs- Maintain brand assets and generic filesEvents & Community- Plan and execute events and promotions- Manage Contacts & Vendors for Event Planning & SponsorshipsOur company is committed to creating a diverse environment and is proud to be an equal opportunity employer. All qualified applicants will receive consideration for employment without regard to race, color, religion, gender, gender identity or expression, sexual orientation, national origin, genetics, disability, age, or veteran status.Job Type: Full-time\nPay: $18-20/hour\nExpected hours: 35 – 45 per week\nBenefits:Paid time offSchedule:8 hour shiftMonday to FridayExperience:Marketing: 1 year (Preferred)Graphic design: 2 years (Preferred)Work Location: In person\n",
         20.0,
         "HOURLY",
         "Princeton, NJ",
         2774458.0,
         20.0,
         null,
         17.0,
         "Full-time",
         2.0,
         1.713397508E12,
         null,
         "https://www.linkedin.com/jobs/view/921716/?trk=jobs_biz_prem_srch",
         null,
         "ComplexOnsiteApply",
         1.715989508E12,
         null,
         null,
         "Requirements: \n\nWe are seeking a College or Graduate Student (can also be completed with school) with a focus in Planning, Architecture, Real Estate Development or Management or General Business. Must be able to work in an extremely fast paced environment and able to multitask and prioritize.",
         1.713397508E12,
         null,
         0,
         "FULL_TIME",
         "USD",
         "BASE_SALARY",
         38480.0,
         8540,
         34021
        ]
       ],
       "datasetInfos": [
        {
         "name": "_sqldf",
         "schema": {
          "fields": [
           {
            "metadata": {},
            "name": "job_id",
            "nullable": true,
            "type": "long"
           },
           {
            "metadata": {},
            "name": "company_name",
            "nullable": true,
            "type": "string"
           },
           {
            "metadata": {},
            "name": "title",
            "nullable": true,
            "type": "string"
           },
           {
            "metadata": {},
            "name": "description",
            "nullable": true,
            "type": "string"
           },
           {
            "metadata": {},
            "name": "max_salary",
            "nullable": true,
            "type": "double"
           },
           {
            "metadata": {},
            "name": "pay_period",
            "nullable": true,
            "type": "string"
           },
           {
            "metadata": {},
            "name": "location",
            "nullable": true,
            "type": "string"
           },
           {
            "metadata": {},
            "name": "company_id",
            "nullable": true,
            "type": "double"
           },
           {
            "metadata": {},
            "name": "views",
            "nullable": true,
            "type": "double"
           },
           {
            "metadata": {},
            "name": "med_salary",
            "nullable": true,
            "type": "double"
           },
           {
            "metadata": {},
            "name": "min_salary",
            "nullable": true,
            "type": "double"
           },
           {
            "metadata": {},
            "name": "formatted_work_type",
            "nullable": true,
            "type": "string"
           },
           {
            "metadata": {},
            "name": "applies",
            "nullable": true,
            "type": "double"
           },
           {
            "metadata": {},
            "name": "original_listed_time",
            "nullable": true,
            "type": "double"
           },
           {
            "metadata": {},
            "name": "remote_allowed",
            "nullable": true,
            "type": "double"
           },
           {
            "metadata": {},
            "name": "job_posting_url",
            "nullable": true,
            "type": "string"
           },
           {
            "metadata": {},
            "name": "application_url",
            "nullable": true,
            "type": "string"
           },
           {
            "metadata": {},
            "name": "application_type",
            "nullable": true,
            "type": "string"
           },
           {
            "metadata": {},
            "name": "expiry",
            "nullable": true,
            "type": "double"
           },
           {
            "metadata": {},
            "name": "closed_time",
            "nullable": true,
            "type": "double"
           },
           {
            "metadata": {},
            "name": "formatted_experience_level",
            "nullable": true,
            "type": "string"
           },
           {
            "metadata": {},
            "name": "skills_desc",
            "nullable": true,
            "type": "string"
           },
           {
            "metadata": {},
            "name": "listed_time",
            "nullable": true,
            "type": "double"
           },
           {
            "metadata": {},
            "name": "posting_domain",
            "nullable": true,
            "type": "string"
           },
           {
            "metadata": {},
            "name": "sponsored",
            "nullable": true,
            "type": "long"
           },
           {
            "metadata": {},
            "name": "work_type",
            "nullable": true,
            "type": "string"
           },
           {
            "metadata": {},
            "name": "currency",
            "nullable": true,
            "type": "string"
           },
           {
            "metadata": {},
            "name": "compensation_type",
            "nullable": true,
            "type": "string"
           },
           {
            "metadata": {},
            "name": "normalized_salary",
            "nullable": true,
            "type": "double"
           },
           {
            "metadata": {},
            "name": "zip_code",
            "nullable": true,
            "type": "long"
           },
           {
            "metadata": {},
            "name": "fips",
            "nullable": true,
            "type": "long"
           }
          ],
          "type": "struct"
         },
         "tableIdentifier": null,
         "typeStr": "pyspark.sql.connect.dataframe.DataFrame"
        }
       ],
       "dbfsResultPath": null,
       "isJsonSchema": true,
       "metadata": {
        "createTempViewForImplicitDf": true,
        "dataframeName": "_sqldf",
        "executionCount": 22
       },
       "overflow": false,
       "plotOptions": {
        "customPlotOptions": {},
        "displayType": "table",
        "pivotAggregation": null,
        "pivotColumns": null,
        "xColumns": null,
        "yColumns": null
       },
       "removedWidgets": [],
       "schema": [
        {
         "metadata": "{}",
         "name": "job_id",
         "type": "\"long\""
        },
        {
         "metadata": "{}",
         "name": "company_name",
         "type": "\"string\""
        },
        {
         "metadata": "{}",
         "name": "title",
         "type": "\"string\""
        },
        {
         "metadata": "{}",
         "name": "description",
         "type": "\"string\""
        },
        {
         "metadata": "{}",
         "name": "max_salary",
         "type": "\"double\""
        },
        {
         "metadata": "{}",
         "name": "pay_period",
         "type": "\"string\""
        },
        {
         "metadata": "{}",
         "name": "location",
         "type": "\"string\""
        },
        {
         "metadata": "{}",
         "name": "company_id",
         "type": "\"double\""
        },
        {
         "metadata": "{}",
         "name": "views",
         "type": "\"double\""
        },
        {
         "metadata": "{}",
         "name": "med_salary",
         "type": "\"double\""
        },
        {
         "metadata": "{}",
         "name": "min_salary",
         "type": "\"double\""
        },
        {
         "metadata": "{}",
         "name": "formatted_work_type",
         "type": "\"string\""
        },
        {
         "metadata": "{}",
         "name": "applies",
         "type": "\"double\""
        },
        {
         "metadata": "{}",
         "name": "original_listed_time",
         "type": "\"double\""
        },
        {
         "metadata": "{}",
         "name": "remote_allowed",
         "type": "\"double\""
        },
        {
         "metadata": "{}",
         "name": "job_posting_url",
         "type": "\"string\""
        },
        {
         "metadata": "{}",
         "name": "application_url",
         "type": "\"string\""
        },
        {
         "metadata": "{}",
         "name": "application_type",
         "type": "\"string\""
        },
        {
         "metadata": "{}",
         "name": "expiry",
         "type": "\"double\""
        },
        {
         "metadata": "{}",
         "name": "closed_time",
         "type": "\"double\""
        },
        {
         "metadata": "{}",
         "name": "formatted_experience_level",
         "type": "\"string\""
        },
        {
         "metadata": "{}",
         "name": "skills_desc",
         "type": "\"string\""
        },
        {
         "metadata": "{}",
         "name": "listed_time",
         "type": "\"double\""
        },
        {
         "metadata": "{}",
         "name": "posting_domain",
         "type": "\"string\""
        },
        {
         "metadata": "{}",
         "name": "sponsored",
         "type": "\"long\""
        },
        {
         "metadata": "{}",
         "name": "work_type",
         "type": "\"string\""
        },
        {
         "metadata": "{}",
         "name": "currency",
         "type": "\"string\""
        },
        {
         "metadata": "{}",
         "name": "compensation_type",
         "type": "\"string\""
        },
        {
         "metadata": "{}",
         "name": "normalized_salary",
         "type": "\"double\""
        },
        {
         "metadata": "{}",
         "name": "zip_code",
         "type": "\"long\""
        },
        {
         "metadata": "{}",
         "name": "fips",
         "type": "\"long\""
        }
       ],
       "type": "table"
      }
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "%sql\n",
    "SELECT * FROM posting.posting_schema.postings LIMIT 1;"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "implicitDf": true,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "fe08a3d8-d0d7-439a-b9e8-679eb80e848c",
     "showTitle": false,
     "tableResultSettingsMap": {},
     "title": ""
    }
   },
   "outputs": [
    {
     "output_type": "display_data",
     "data": {
      "text/html": [
       "<style scoped>\n",
       "  .table-result-container {\n",
       "    max-height: 300px;\n",
       "    overflow: auto;\n",
       "  }\n",
       "  table, th, td {\n",
       "    border: 1px solid black;\n",
       "    border-collapse: collapse;\n",
       "  }\n",
       "  th, td {\n",
       "    padding: 5px;\n",
       "  }\n",
       "  th {\n",
       "    text-align: left;\n",
       "  }\n",
       "</style><div class='table-result-container'><table class='table-result'><thead style='background-color: white'><tr><th>col_name</th><th>data_type</th><th>comment</th></tr></thead><tbody><tr><td>job_id</td><td>bigint</td><td>null</td></tr><tr><td>company_name</td><td>string</td><td>null</td></tr><tr><td>title</td><td>string</td><td>null</td></tr><tr><td>description</td><td>string</td><td>null</td></tr><tr><td>max_salary</td><td>double</td><td>null</td></tr><tr><td>pay_period</td><td>string</td><td>null</td></tr><tr><td>location</td><td>string</td><td>null</td></tr><tr><td>company_id</td><td>double</td><td>null</td></tr><tr><td>views</td><td>double</td><td>null</td></tr><tr><td>med_salary</td><td>double</td><td>null</td></tr><tr><td>min_salary</td><td>double</td><td>null</td></tr><tr><td>formatted_work_type</td><td>string</td><td>null</td></tr><tr><td>applies</td><td>double</td><td>null</td></tr><tr><td>original_listed_time</td><td>double</td><td>null</td></tr><tr><td>remote_allowed</td><td>double</td><td>null</td></tr><tr><td>job_posting_url</td><td>string</td><td>null</td></tr><tr><td>application_url</td><td>string</td><td>null</td></tr><tr><td>application_type</td><td>string</td><td>null</td></tr><tr><td>expiry</td><td>double</td><td>null</td></tr><tr><td>closed_time</td><td>double</td><td>null</td></tr><tr><td>formatted_experience_level</td><td>string</td><td>null</td></tr><tr><td>skills_desc</td><td>string</td><td>null</td></tr><tr><td>listed_time</td><td>double</td><td>null</td></tr><tr><td>posting_domain</td><td>string</td><td>null</td></tr><tr><td>sponsored</td><td>bigint</td><td>null</td></tr><tr><td>work_type</td><td>string</td><td>null</td></tr><tr><td>currency</td><td>string</td><td>null</td></tr><tr><td>compensation_type</td><td>string</td><td>null</td></tr><tr><td>normalized_salary</td><td>double</td><td>null</td></tr><tr><td>zip_code</td><td>bigint</td><td>null</td></tr><tr><td>fips</td><td>bigint</td><td>null</td></tr></tbody></table></div>"
      ]
     },
     "metadata": {
      "application/vnd.databricks.v1+output": {
       "addedWidgets": {},
       "aggData": [],
       "aggError": "",
       "aggOverflow": false,
       "aggSchema": [],
       "aggSeriesLimitReached": false,
       "aggType": "",
       "arguments": {},
       "columnCustomDisplayInfos": {},
       "data": [
        [
         "job_id",
         "bigint",
         null
        ],
        [
         "company_name",
         "string",
         null
        ],
        [
         "title",
         "string",
         null
        ],
        [
         "description",
         "string",
         null
        ],
        [
         "max_salary",
         "double",
         null
        ],
        [
         "pay_period",
         "string",
         null
        ],
        [
         "location",
         "string",
         null
        ],
        [
         "company_id",
         "double",
         null
        ],
        [
         "views",
         "double",
         null
        ],
        [
         "med_salary",
         "double",
         null
        ],
        [
         "min_salary",
         "double",
         null
        ],
        [
         "formatted_work_type",
         "string",
         null
        ],
        [
         "applies",
         "double",
         null
        ],
        [
         "original_listed_time",
         "double",
         null
        ],
        [
         "remote_allowed",
         "double",
         null
        ],
        [
         "job_posting_url",
         "string",
         null
        ],
        [
         "application_url",
         "string",
         null
        ],
        [
         "application_type",
         "string",
         null
        ],
        [
         "expiry",
         "double",
         null
        ],
        [
         "closed_time",
         "double",
         null
        ],
        [
         "formatted_experience_level",
         "string",
         null
        ],
        [
         "skills_desc",
         "string",
         null
        ],
        [
         "listed_time",
         "double",
         null
        ],
        [
         "posting_domain",
         "string",
         null
        ],
        [
         "sponsored",
         "bigint",
         null
        ],
        [
         "work_type",
         "string",
         null
        ],
        [
         "currency",
         "string",
         null
        ],
        [
         "compensation_type",
         "string",
         null
        ],
        [
         "normalized_salary",
         "double",
         null
        ],
        [
         "zip_code",
         "bigint",
         null
        ],
        [
         "fips",
         "bigint",
         null
        ]
       ],
       "datasetInfos": [
        {
         "name": "_sqldf",
         "schema": {
          "fields": [
           {
            "metadata": {},
            "name": "col_name",
            "nullable": false,
            "type": "string"
           },
           {
            "metadata": {},
            "name": "data_type",
            "nullable": false,
            "type": "string"
           },
           {
            "metadata": {},
            "name": "comment",
            "nullable": true,
            "type": "string"
           }
          ],
          "type": "struct"
         },
         "tableIdentifier": null,
         "typeStr": "pyspark.sql.connect.dataframe.DataFrame"
        }
       ],
       "dbfsResultPath": null,
       "isJsonSchema": true,
       "metadata": {
        "createTempViewForImplicitDf": true,
        "dataframeName": "_sqldf",
        "executionCount": 64
       },
       "overflow": false,
       "plotOptions": {
        "customPlotOptions": {},
        "displayType": "table",
        "pivotAggregation": null,
        "pivotColumns": null,
        "xColumns": null,
        "yColumns": null
       },
       "removedWidgets": [],
       "schema": [
        {
         "metadata": "{}",
         "name": "col_name",
         "type": "\"string\""
        },
        {
         "metadata": "{}",
         "name": "data_type",
         "type": "\"string\""
        },
        {
         "metadata": "{}",
         "name": "comment",
         "type": "\"string\""
        }
       ],
       "type": "table"
      }
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "%sql\n",
    "DESCRIBE TABLE `posting_schema`.`postings`;"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {},
     "collapsed": true,
     "inputWidgets": {},
     "nuid": "6d9c8d0a-536b-4eb3-af97-b7944d02dc26",
     "showTitle": false,
     "tableResultSettingsMap": {},
     "title": ""
    },
    "jupyter": {
     "outputs_hidden": true
    }
   },
   "outputs": [
    {
     "output_type": "display_data",
     "data": {
      "text/html": [
       "<style scoped>\n",
       "  .ansiout {\n",
       "    display: block;\n",
       "    unicode-bidi: embed;\n",
       "    white-space: pre-wrap;\n",
       "    word-wrap: break-word;\n",
       "    word-break: break-all;\n",
       "    font-family: \"Menlo\", \"Monaco\", \"Consolas\", \"Ubuntu Mono\", \"Source Code Pro\", monospace;\n",
       "    font-size: 13px;\n",
       "    color: #555;\n",
       "    margin-left: 4px;\n",
       "    line-height: 19px;\n",
       "  }\n",
       "</style>"
      ]
     },
     "metadata": {
      "application/vnd.databricks.v1+output": {
       "arguments": {},
       "data": "",
       "errorSummary": "Cancelled",
       "errorTraceType": null,
       "metadata": {},
       "type": "ipynbError"
      }
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "# df = spark.read.csv('/home/spark-97ea63cc-1f68-4087-991d-08/.cache/kagglehub/datasets/arshkon/linkedin-job-postings/versions/13')\n",
    "# df.show(10)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "implicitDf": true,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "daf76022-266b-458a-8b53-bce735d9e1f7",
     "showTitle": false,
     "tableResultSettingsMap": {},
     "title": ""
    }
   },
   "outputs": [],
   "source": [
    "%sql\n",
    "use posting.posting_schema;"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "implicitDf": true,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "8cfbb8a7-f16a-4ea0-90fd-1f0d4c308439",
     "showTitle": false,
     "tableResultSettingsMap": {},
     "title": ""
    }
   },
   "outputs": [
    {
     "output_type": "display_data",
     "data": {
      "text/html": [
       "<style scoped>\n",
       "  .table-result-container {\n",
       "    max-height: 300px;\n",
       "    overflow: auto;\n",
       "  }\n",
       "  table, th, td {\n",
       "    border: 1px solid black;\n",
       "    border-collapse: collapse;\n",
       "  }\n",
       "  th, td {\n",
       "    padding: 5px;\n",
       "  }\n",
       "  th {\n",
       "    text-align: left;\n",
       "  }\n",
       "</style><div class='table-result-container'><table class='table-result'><thead style='background-color: white'><tr><th>MinSalary</th></tr></thead><tbody><tr><td>17.0</td></tr></tbody></table></div>"
      ]
     },
     "metadata": {
      "application/vnd.databricks.v1+output": {
       "addedWidgets": {},
       "aggData": [],
       "aggError": "",
       "aggOverflow": false,
       "aggSchema": [],
       "aggSeriesLimitReached": false,
       "aggType": "",
       "arguments": {},
       "columnCustomDisplayInfos": {},
       "data": [
        [
         17.0
        ]
       ],
       "datasetInfos": [
        {
         "name": "_sqldf",
         "schema": {
          "fields": [
           {
            "metadata": {},
            "name": "MinSalary",
            "nullable": true,
            "type": "float"
           }
          ],
          "type": "struct"
         },
         "tableIdentifier": null,
         "typeStr": "pyspark.sql.connect.dataframe.DataFrame"
        }
       ],
       "dbfsResultPath": null,
       "isJsonSchema": true,
       "metadata": {
        "createTempViewForImplicitDf": true,
        "dataframeName": "_sqldf",
        "executionCount": 31
       },
       "overflow": false,
       "plotOptions": {
        "customPlotOptions": {},
        "displayType": "table",
        "pivotAggregation": null,
        "pivotColumns": null,
        "xColumns": null,
        "yColumns": null
       },
       "removedWidgets": [],
       "schema": [
        {
         "metadata": "{}",
         "name": "MinSalary",
         "type": "\"float\""
        }
       ],
       "type": "table"
      }
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "%sql\n",
    "CREATE OR REPLACE FUNCTION get_min_salary(postingJobID STRING)\n",
    "RETURNS FLOAT\n",
    "LANGUAGE SQL\n",
    "COMMENT 'Gets the minimum salary for the corresponding postingJobID'\n",
    "RETURN (SELECT MIN(min_salary) FROM posting.posting_schema.postings WHERE job_id = postingJobID);\n",
    "\n",
    "-- let's test our function:\n",
    "SELECT get_min_salary(921716) as MinSalary;"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "implicitDf": true,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "c51a35d1-b94e-4d3f-a3ce-7a26378284fa",
     "showTitle": false,
     "tableResultSettingsMap": {},
     "title": ""
    }
   },
   "outputs": [
    {
     "output_type": "display_data",
     "data": {
      "text/html": [
       "<style scoped>\n",
       "  .table-result-container {\n",
       "    max-height: 300px;\n",
       "    overflow: auto;\n",
       "  }\n",
       "  table, th, td {\n",
       "    border: 1px solid black;\n",
       "    border-collapse: collapse;\n",
       "  }\n",
       "  th, td {\n",
       "    padding: 5px;\n",
       "  }\n",
       "  th {\n",
       "    text-align: left;\n",
       "  }\n",
       "</style><div class='table-result-container'><table class='table-result'><thead style='background-color: white'><tr><th>job_ID</th><th>companyName</th><th>Title</th><th>description</th><th>location</th><th>max_salary</th><th>med_salary</th><th>min_salary</th><th>skills_desc</th><th>post_date</th></tr></thead><tbody><tr><td>12345</td><td>Google</td><td>Data Scientist</td><td>Develop and apply machine learning models to drive business decisions</td><td>New York</td><td>150000.0</td><td>120000.0</td><td>90000.0</td><td>Python, R, SQL, TensorFlow, Keras</td><td>2022-01-01</td></tr><tr><td>67890</td><td>Microsoft</td><td>Senior Data Analyst</td><td>Analyze complex data sets to inform product development and marketing strategies</td><td>San Francisco</td><td>180000.0</td><td>140000.0</td><td>100000.0</td><td>Excel, SQL, Tableau, Power BI, Statistics</td><td>2022-02-01</td></tr><tr><td>34567</td><td>Amazon</td><td>Machine Learning Engineer</td><td>Design and deploy scalable machine learning models to drive customer engagement</td><td>Seattle</td><td>200000.0</td><td>160000.0</td><td>120000.0</td><td>Java, Python, Scala, Spark, Hadoop</td><td>2022-03-01</td></tr></tbody></table></div>"
      ]
     },
     "metadata": {
      "application/vnd.databricks.v1+output": {
       "addedWidgets": {},
       "aggData": [],
       "aggError": "",
       "aggOverflow": false,
       "aggSchema": [],
       "aggSeriesLimitReached": false,
       "aggType": "",
       "arguments": {},
       "columnCustomDisplayInfos": {},
       "data": [
        [
         12345,
         "Google",
         "Data Scientist",
         "Develop and apply machine learning models to drive business decisions",
         "New York",
         150000.0,
         120000.0,
         90000.0,
         "Python, R, SQL, TensorFlow, Keras",
         "2022-01-01"
        ],
        [
         67890,
         "Microsoft",
         "Senior Data Analyst",
         "Analyze complex data sets to inform product development and marketing strategies",
         "San Francisco",
         180000.0,
         140000.0,
         100000.0,
         "Excel, SQL, Tableau, Power BI, Statistics",
         "2022-02-01"
        ],
        [
         34567,
         "Amazon",
         "Machine Learning Engineer",
         "Design and deploy scalable machine learning models to drive customer engagement",
         "Seattle",
         200000.0,
         160000.0,
         120000.0,
         "Java, Python, Scala, Spark, Hadoop",
         "2022-03-01"
        ]
       ],
       "datasetInfos": [
        {
         "name": "_sqldf",
         "schema": {
          "fields": [
           {
            "metadata": {},
            "name": "job_ID",
            "nullable": true,
            "type": "long"
           },
           {
            "metadata": {},
            "name": "companyName",
            "nullable": true,
            "type": "string"
           },
           {
            "metadata": {},
            "name": "Title",
            "nullable": true,
            "type": "string"
           },
           {
            "metadata": {},
            "name": "description",
            "nullable": true,
            "type": "string"
           },
           {
            "metadata": {},
            "name": "location",
            "nullable": true,
            "type": "string"
           },
           {
            "metadata": {},
            "name": "max_salary",
            "nullable": true,
            "type": "double"
           },
           {
            "metadata": {},
            "name": "med_salary",
            "nullable": true,
            "type": "double"
           },
           {
            "metadata": {},
            "name": "min_salary",
            "nullable": true,
            "type": "double"
           },
           {
            "metadata": {},
            "name": "skills_desc",
            "nullable": true,
            "type": "string"
           },
           {
            "metadata": {},
            "name": "post_date",
            "nullable": true,
            "type": "string"
           }
          ],
          "type": "struct"
         },
         "tableIdentifier": null,
         "typeStr": "pyspark.sql.connect.dataframe.DataFrame"
        }
       ],
       "dbfsResultPath": null,
       "isJsonSchema": true,
       "metadata": {
        "createTempViewForImplicitDf": true,
        "dataframeName": "_sqldf",
        "executionCount": 156
       },
       "overflow": false,
       "plotOptions": {
        "customPlotOptions": {},
        "displayType": "table",
        "pivotAggregation": null,
        "pivotColumns": null,
        "xColumns": null,
        "yColumns": null
       },
       "removedWidgets": [],
       "schema": [
        {
         "metadata": "{}",
         "name": "job_ID",
         "type": "\"long\""
        },
        {
         "metadata": "{}",
         "name": "companyName",
         "type": "\"string\""
        },
        {
         "metadata": "{}",
         "name": "Title",
         "type": "\"string\""
        },
        {
         "metadata": "{}",
         "name": "description",
         "type": "\"string\""
        },
        {
         "metadata": "{}",
         "name": "location",
         "type": "\"string\""
        },
        {
         "metadata": "{}",
         "name": "max_salary",
         "type": "\"double\""
        },
        {
         "metadata": "{}",
         "name": "med_salary",
         "type": "\"double\""
        },
        {
         "metadata": "{}",
         "name": "min_salary",
         "type": "\"double\""
        },
        {
         "metadata": "{}",
         "name": "skills_desc",
         "type": "\"string\""
        },
        {
         "metadata": "{}",
         "name": "post_date",
         "type": "\"string\""
        }
       ],
       "type": "table"
      }
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "%sql\n",
    "-- Generate fake data instead of calling the VS index with vector_search;\n",
    "CREATE OR REPLACE FUNCTION find_jobs_matching_description (description STRING)\n",
    "RETURNS TABLE (job_ID BIGINT, companyName STRING, Title STRING, description STRING, location STRING, max_salary DOUBLE, med_salary DOUBLE, min_salary DOUBLE, skills_desc STRING, post_date STRING)\n",
    "COMMENT 'Finds existing jobs matching the description using AI query and returns a table of results.'\n",
    "RETURN\n",
    "SELECT jobs.* FROM (\n",
    "  SELECT explode(from_json(\n",
    "    ai_query(\n",
    "      'databricks-meta-llama-3-70b-instruct', \n",
    "      CONCAT(\n",
    "        'returns a json list of 3 json object postings: <job_ID BIGINT, companyName STRING, Title STRING, description STRING, location STRING, max_salary DOUBLE, med_salary DOUBLE, min_salary DOUBLE, skills_desc STRING, post_date STRING>. These postings should match the following user description: ', description, '. Return only the answer as a javascript json object ready to be parsed, no comment or text or javascript or ``` at the beginning.' ) ), 'ARRAY<STRUCT<job_ID: BIGINT, companyName: STRING, Title: STRING, description: STRING, location: STRING, max_salary: FLOAT, med_salary: FLOAT, min_salary: DOUBLE, skills_desc: STRING, post_date: STRING>>' )) AS jobs );\n",
    "\n",
    "-- let's test our function:\n",
    "SELECT * FROM find_jobs_matching_description('data science');"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "implicitDf": true,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "fe435028-944f-4616-bd2b-5c781225d48c",
     "showTitle": false,
     "tableResultSettingsMap": {},
     "title": ""
    }
   },
   "outputs": [
    {
     "output_type": "display_data",
     "data": {
      "text/html": [
       "<style scoped>\n",
       "  .table-result-container {\n",
       "    max-height: 300px;\n",
       "    overflow: auto;\n",
       "  }\n",
       "  table, th, td {\n",
       "    border: 1px solid black;\n",
       "    border-collapse: collapse;\n",
       "  }\n",
       "  th, td {\n",
       "    padding: 5px;\n",
       "  }\n",
       "  th {\n",
       "    text-align: left;\n",
       "  }\n",
       "</style><div class='table-result-container'><table class='table-result'><thead style='background-color: white'><tr><th>job_id</th><th>company_name</th><th>title</th><th>description</th><th>max_salary</th><th>pay_period</th><th>location</th><th>company_id</th><th>views</th><th>med_salary</th><th>min_salary</th><th>formatted_work_type</th><th>applies</th><th>original_listed_time</th><th>remote_allowed</th><th>job_posting_url</th><th>application_url</th><th>application_type</th><th>expiry</th><th>closed_time</th><th>formatted_experience_level</th><th>skills_desc</th><th>listed_time</th><th>posting_domain</th><th>sponsored</th><th>work_type</th><th>currency</th><th>compensation_type</th><th>normalized_salary</th><th>zip_code</th><th>fips</th></tr></thead><tbody><tr><td>3884822884</td><td>Stanford University</td><td>Research Data Analyst 1 (75% FTE/Hybrid Opportunity)</td><td>The Department of Psychiatry and Behavioral Sciences at Stanford University’s School of Medicine is seeking Research Data Analyst (RDA 1) 1 to manage and analyze large amounts of multi-modality brain imaging data under the direction of Dr. Vankee Lin. CogT Lab focuses on the evaluation of various cognitive interventions among older adults and understanding the underlying neural mechanisms. For more information on the lab, please visit: https://www.cogtlab.com/\n",
       "\n",
       "This position will be 75% FTE. Interested candidates should include a cover letter along with their CV.\n",
       "\n",
       "Duties Include\n",
       "\n",
       " Manage and clean datasets. Employ new and existing tools to interpret, analyze, and visualize multivariate relationships in data. Create databases and reports, develop algorithms and statistical and/or computational models, and perform data analyses appropriate to data and reporting requirements. Use system reports and analyses to identify potentially problematic data, make corrections, and determine root cause for data problems from input errors or inadequate field edits, and suggest possible solutions. Develop reports, charts, graphs and tables for use by investigators and for publication and presentation. Analyze data processes in documentation. Collaborate with faculty and research staff on data collection and analysis methods. Provide documentation based on audit and reporting criteria to investigators and research staff. Communicate with government officials, grant agencies and industry representatives.  - Other duties may also be assigned\n",
       "\n",
       "\n",
       "Desired Qualifications\n",
       "\n",
       "Bachelor's degree in computational and engineering sciences (e.g., computer science, computational biology, electrical engineering, biomedical engineering) or other related fields. Experience with signal processing of medical imaging data. Experience with or demonstrated interest in neuroimaging techniques. Experience with Neuroimaging (FSL, SPM, AFNI, or equivalent) software. Experience using high-performance computer clusters and bash/shell scripting. Experience in data science, statistics, optimization, machine learning, and/or deep learning. Experience with machine learning frameworks (e.g. PyTorch, Tensorflow, etc.) Experience with Statistical software (R, SAS, SPSS, or equivalent), and other common programming languages in neuroimaging (python, MATLAB). Prior experience with R is highly recommended for data analysis. \n",
       "\n",
       "\n",
       "Education & Experience (required)\n",
       "\n",
       " Bachelor's degree or a combination of education and relevant experience. Experience in a quantitative discipline such as economics, finance, statistics or engineering. \n",
       "\n",
       "\n",
       "Knowledge, Skills And Abilities (required)\n",
       "\n",
       "Substantial experience with MS Office and analytical programs Strong writing and analytical skills in machine learning. Ability to prioritize workload. \n",
       "\n",
       "\n",
       "PHYSICAL REQUIREMENTS*:\n",
       "\n",
       " Sitting in place at computer for long periods of time with extensive keyboarding/dexterity. Occasionally use a telephone. Rarely writing by hand.  - Consistent with its obligations under the law, the University will provide reasonable accommodation to any employee with a disability who requires accommodation to perform the essential functions of his or her job.\n",
       "\n",
       "\n",
       "Working Conditions\n",
       "\n",
       "Some work may be performed in a laboratory or field setting. This position is based in Stanford’s Research Park and has the option of a telecommuting/hybrid schedule subject to operational needs. This position is 75% FTE. \n",
       "\n",
       "\n",
       "The expected pay range for this position is $48,360 to $72,750 per annum. Stanford University provides pay ranges representing its good faith estimate of what the university reasonably expects to pay for a position. The pay offered to a selected candidate will be determined based on factors such as (but not limited to) the scope and responsibilities of the position, the qualifications of the selected candidate, departmental budget availability, internal equity, geographic location and external market pay for comparable jobs.\n",
       "\n",
       " - Stanford is an equal employment opportunity and affirmative action employer. All qualified applicants will receive consideration for employment without regard to race, color, religion, sex, sexual orientation, gender identity, national origin, disability, protected veteran status, or any other characteristic protected by law</td><td>72750.0</td><td>YEARLY</td><td>Stanford, CA</td><td>1792.0</td><td>12.0</td><td>null</td><td>48360.0</td><td>Part-time</td><td>1.0</td><td>1.712372056E12</td><td>null</td><td>https://www.linkedin.com/jobs/view/3884822884/?trk=jobs_biz_prem_srch</td><td>https://stanford.taleo.net/careersection/2/jobdetail.ftl?utm_medium=campaign&job=102822&lang=en&utm_source=linkedin</td><td>OffsiteApply</td><td>1.714964771E12</td><td>null</td><td>Mid-Senior level</td><td>null</td><td>1.712372771E12</td><td>stanford.taleo.net</td><td>0</td><td>PART_TIME</td><td>USD</td><td>BASE_SALARY</td><td>60555.0</td><td>94305</td><td>6085</td></tr><tr><td>3886150898</td><td>Reworkd AI (YC S23)</td><td>Founding Engineer</td><td>About ReworkdAt Reworkd, we’re working on multi-modal LLM agents to extract structured web data at scale. Since inception, Reworkd has been one of the leaders in AI Agents, having built and scaled AgentGPT to over 1M+ monthly users.\n",
       "We are a team of engineers and operators from leading CS universities such as UBC, CMU and SFU. Our team has prior experience at organizations such as AWS, Article and Microsoft. Currently a small, fast moving team of four, we’ve built every layer our our LLM/Agent stack including: evals, prompt design, LLM/Agent routing and custom OCR pipelines.\n",
       "Additionally, we’re backed by top to tier investors including YCombinator, SV Angel, General Catalyst, Panache Ventures, and many more.\n",
       "About your role:As a founding backend engineer at Reworkd, you will help shape the future of LLM agents taking web actions. In your first month you may:Build a robust queuing system to handle 1M+ compute heavy (playwright) jobs a dayMigrate an existing pool of batch workers off of AWS to bare metalEnhance autoscaling / deployment strategy using K8s or similar technologiesGive our code generation agents additional superpowers (eg: captcha solving. crawling, etc…)\n",
       "ResponsibilitiesLeading and collaborating on mission critical features / bugsPromoting engineering best practices throughout the rest of the teamEnsuring that our tech stack is able to scale with our hyper growth\n",
       "Qualifications and Skills:Located in the bay area or able to relocate to the bay areaExpertise in writing production grade python (+typescript). Bonus if you have experience with NextJS, FastAPI, and SQLAlchemy/SQLModel.Prior experience building and managing distributed / batch job systemsProficiency with optimizing queries in MySQL, Postgres, or similar SQL based databaseExperienced with hosting on AWS and/or bare metal (knowledge of K8s is a plus)Prior experience as an operator or founding employee at another startupDeep knowledge of modern web automation techniques (eg: selenium, playwright, CDP protocol, proxies etc..)Ability to operate with a high sense of agency\n",
       "Compensation:The base compensation for this role is $130,000 - $170,000 USD per year. In addition, you will also receive equity-based compensation, a top tier medical / dental / vision plan, and unlimited PTO. In addition, we also host weekly team outings, team dinners and will even give you a haircut (no seriously, our COO is a barber).\n",
       "Interview Process:We like to keep interview loops short but want actual in person working sessions so each of us can determine if we’re the right fitFirst step: 30 min intro call with a founderSecond step: 1 hour call with founding team + pair programming sessionsThird step: Two paid weeks of in person work, this is your chance to make sure we are also a good fit for you.Decision: we'll get back to you within a week of the final interview.\n",
       "Reworkd is committed to fostering and empowering an inclusive community within our organization. We do not discriminate on the basis of race, religion, color, gender expression or identity, sexual orientation, national origin, citizenship, age, marital status, veteran status, disability status, or any other characteristic protected by law. Reworkd encourages everyone to apply for our available positions, even if they don't necessarily check every box on the job description.\n",
       "Reworkd is an in-person company, our brand new office is located in the heart of San Francisco. Successful candidates will be required to relocate if they do not already live in the bay area.</td><td>170000.0</td><td>YEARLY</td><td>San Francisco Bay Area</td><td>9.1361772E7</td><td>16.0</td><td>null</td><td>130000.0</td><td>Full-time</td><td>2.0</td><td>1.712894808E12</td><td>null</td><td>https://www.linkedin.com/jobs/view/3886150898/?trk=jobs_biz_prem_srch</td><td>null</td><td>ComplexOnsiteApply</td><td>1.715486808E12</td><td>null</td><td>null</td><td>null</td><td>1.712894808E12</td><td>null</td><td>0</td><td>FULL_TIME</td><td>USD</td><td>BASE_SALARY</td><td>150000.0</td><td>null</td><td>null</td></tr><tr><td>3886896623</td><td>Ascendion</td><td>Full Stack Developer</td><td>About Ascendion:Ascendion is a full-service digital engineering solutions company. We make and manage software platforms and products that power growth and deliver captivating experiences to consumers and employees. Our engineering, cloud, data, experience design, and talent solution capabilities accelerate transformation and impact for enterprise clients. Headquartered in New Jersey, our workforce of 6,000+ Ascenders delivers solutions from around the globe. Ascendion is built differently to engineer the next. Ascendion | Engineering to elevate life\n",
       "We have a culture built on opportunity, inclusion, and a spirit of partnership. Come, change the world with us:Build the coolest tech for world’s leading brandsSolve complex problems – and learn new skillsExperience the power of transforming digital engineering for Fortune 500 clientsMaster your craft with leading training programs and hands-on experience\n",
       "Experience a community of change makers!Join a culture of high-performing innovators with endless ideas and a passion for tech. Our culture is the fabric of our company, and it is what makes us unique and diverse. The way we share ideas, learning, experiences, successes, and joy allows everyone to be their best at Ascendion.\n",
       "About the Role:Job Title: Full Stack Developer\n",
       "Location: Chicago, IL/Houston, TX (Hybrid)\n",
       "Key Responsibilities:The Full stack Developer will advance the develop and deliver quality solutions using Node.js, HTTP, REST, NoSQL, and other web technologies.Work with minimum technical supervision and supplemental engineering support.Design and develop enhancements on new and existing applications using Node.js.Proficient understanding of code versioning tools, such as Git/SVN.\n",
       "Minimum Qualifications:Bachelor's Degree and three years of work experience, or in lieu of a Bachelor's5+ years of experience with Node JS developing APIs (must have), and nice to have knowledge of python, and/or other scripting languages, express.js, next.js5 years’ experience implementing AWS technologies.Experience with Cloud Automation Development Tool such as Git, Python/Bash/PowerShell ScriptingHands-on development and proficient excellence in backend API development using Node.js.Expertise in building REST-based microservices in a serverless architecture.Experience and thorough understanding of NoSQL databases like DynamoDB.Familiarity with event/message-driven system design and architecture.Experience writing tests and executing them using Node Lambda.Experience in agile environmentOral and written communication skills\n",
       "Salary Range: The salary for this position is between $100,000 – $115,000 annually. Factors which may affect pay within this range may include geography/market, skills, education, experience, and other qualifications of the successful candidate.\n",
       "This position is eligible for commissions in accordance with the terms of the Company’s plan. Commissions for this position are estimated to be based on individual performance. Additionally, this role is also eligible for bonus based on achievement of mutually agreed KRAs.\n",
       "Benefits: The Company offers the following benefits for this position, subject to applicable eligibility requirements: [medical insurance] [dental insurance] [vision insurance] [401(k) retirement plan] [long-term disability insurance] [short-term disability insurance] [personal days accrued each calendar year. The Paid time off benefits meet the paid sick and safe time laws that pertains to the City/ State] [12-15 days of paid vacation time] [6-8 weeks of paid parental leave after a year of service] [9 paid holidays and 2 floating holidays per calendar year] [Ascendion Learning Management System] [Tuition Reimbursement Program]\n",
       "Want to change the world? Let us know.Tell us about your experiences, education, and ambitions. Bring your knowledge, unique viewpoint, and creativity to the table. Let’s talk!</td><td>115000.0</td><td>YEARLY</td><td>Chicago, IL</td><td>8.669468E7</td><td>200.0</td><td>null</td><td>100000.0</td><td>Full-time</td><td>83.0</td><td>1.712668075E12</td><td>null</td><td>https://www.linkedin.com/jobs/view/3886896623/?trk=jobs_biz_prem_srch</td><td>null</td><td>ComplexOnsiteApply</td><td>1.715260075E12</td><td>null</td><td>Mid-Senior level</td><td>null</td><td>1.712668075E12</td><td>null</td><td>0</td><td>FULL_TIME</td><td>USD</td><td>BASE_SALARY</td><td>107500.0</td><td>60601</td><td>17031</td></tr><tr><td>3886964478</td><td>Cornerstone Defense</td><td>Network Engineer (Clearance Required) </td><td>Network EngineerSunnyvale, CAActive Secret or Top SecretJob Responsibilities:Network hardware & software expertise in support of the Combined Orbital Operations Logistics and Resiliency (COOLR)contract on Factory AEHF System Database (ASDB), Flight Software (FSW) and Network AEHF System Testbed - Tools (NAST-T) activities.existing Network & NetApp Filer configurations and practices, and recommend refinements, improvements, and performance enhancements to align with industry best practices and Security compliance requirements.administration, system backups and troubleshooting the Network (Windows/Unix/LINUX) servers and NetApp filer storage array.Required Skills:IT administration including experience with installation, configuration, and maintenance of Windows/UNIX/LINUX servers and network IT infrastructure.with maintaining Oracle database servers.with of networked database server and NetApp filers.with developing and debugging related scripts in UNIX shell scripting languages, Perl, or python.understanding of software and database development processes.</td><td>150000.0</td><td>YEARLY</td><td>Sunnyvale, CA</td><td>3772194.0</td><td>6.0</td><td>null</td><td>130000.0</td><td>Full-time</td><td>null</td><td>1.713460223E12</td><td>null</td><td>https://www.linkedin.com/jobs/view/3886964478/?trk=jobs_biz_prem_srch</td><td>null</td><td>ComplexOnsiteApply</td><td>1.716052223E12</td><td>null</td><td>null</td><td>null</td><td>1.713460223E12</td><td>null</td><td>0</td><td>FULL_TIME</td><td>USD</td><td>BASE_SALARY</td><td>140000.0</td><td>94085</td><td>null</td></tr><tr><td>3887716794</td><td>Kavaliro</td><td>Electrical Engineer</td><td>Kavaliro is seeking an Electrical Engineer for an innovative company focused on research and development with a substantial concentration on hydrogen within the renewable energy sector. We leverage intellectual property with cutting-edge technology and materials to create novel solutions for many challenges the energy industry is facing today and will face in the future. With a multidisciplinary structure in an environment focused on collaboration, we value employee professional development in parallel with company success. If you are interested in working with a passionate engineering team to achieve groundbreaking value, we invite you to apply.\n",
       " \n",
       " \n",
       " \n",
       " Roles and Responsibilities:\n",
       " \n",
       " - Design electrical and automated control systems, AC and DC power systems, and electromechanical systems in a manufacturing process.\n",
       " \n",
       " - Integrate components including digital and analog sensors, communication devices, AC and DC motors, and heating elements.\n",
       " \n",
       " - Troubleshoot I/O connections, wiring, program logic, and power systems.\n",
       " \n",
       " - Purchase components and manage vendor relationships.\n",
       " \n",
       " - Develop software to test and operate systems in ladder logic and on other development platforms.\n",
       " \n",
       " - Create schematics for designs.\n",
       " \n",
       " - Communicate and present designs and results to a cross-functional engineering team.\n",
       " \n",
       " - Provide feedback on system level designs.\n",
       " \n",
       " \n",
       " \n",
       " \n",
       "Requirements:\n",
       " \n",
       " - Bachelor’s degree in Electrical Engineering.\n",
       " \n",
       " - Experience in circuit design, component selection, integration, and testing.\n",
       " \n",
       " - Experience with wiring low-voltage controls components and circuits.\n",
       " \n",
       " - Experience with PLC’s.\n",
       " \n",
       " - Programming experience in ladder logic, python, C, or related language.\n",
       " \n",
       " - Understanding of core electrical concepts related to controls systems.\n",
       " \n",
       " - Understanding of different motor types and applications.\n",
       " \n",
       " - Proficient with hand and power tool operation and safety.\n",
       " \n",
       " - CAD experience.\n",
       " \n",
       " \n",
       " \n",
       "\n",
       "Kavaliro provides Equal Employment Opportunities to all employees and applicants. All qualified applicants will receive consideration for employment without regard to race, color, religion, age, sex, national origin, disability status, genetics, protected veteran status, sexual orientation, gender identity or expression, or any other characteristic protected by federal, state, or local laws. Kavaliro is committed to the full inclusion of all qualified individuals. In keeping with our commitment, Kavaliro will take steps to assure that people with disabilities are provided reasonable accommodations. Accordingly, if reasonable accommodation is required to fully participate in the job application or interview process, to perform the essential functions of the position, and/or to receive all other benefits and privileges of employment, please respond to this posting to connect with a company representative.</td><td>85000.0</td><td>YEARLY</td><td>Jacksonville, FL</td><td>1070686.0</td><td>13.0</td><td>null</td><td>75000.0</td><td>Full-time</td><td>1.0</td><td>1.712350491E12</td><td>null</td><td>https://www.linkedin.com/jobs/view/3887716794/?trk=jobs_biz_prem_srch</td><td>https://www.aptrack.co/uap/AAAGoQAPjHwCPYFP/</td><td>OffsiteApply</td><td>1.7149422E12</td><td>null</td><td>Mid-Senior level</td><td>null</td><td>1.712350491E12</td><td>www.aptrack.co</td><td>0</td><td>FULL_TIME</td><td>USD</td><td>BASE_SALARY</td><td>80000.0</td><td>32099</td><td>12031</td></tr><tr><td>3887873255</td><td>Vaxcyte</td><td>Sr. Associate Engineer, Polysaccharide Process Development</td><td>Join our Mission to Protect Humankind!\n",
       "\n",
       "Vaxcyte is a clinical-stage vaccine innovation company engineering high-fidelity vaccines to protect humankind from the consequences of bacterial diseases, which have serious and costly health consequences when left unchecked. Working to eradicate or treat bacterial infections such as invasive pneumococcal disease, Group A Strep, periodontitis and Shigella is just the beginning. Our path to success is clear and well-defined, and Vaxcyte is set up to go the distance.\n",
       "\n",
       "WHAT we do is every bit as important as HOW we do it! Our work together is guided by four enduring core values:\n",
       "\n",
       "AIM HIGH: We embody our collectively audacious goal to courageously make the most complex biologics ever attempted to protect humankind. LEAD WITH HEART: Everyone leads at Vaxcyte with a kindness-first, inclusive approach to collaboration and vigorous debate that advances our business objectives. RETHINK CONVENTION: We bring creative and intellectual diversity to every facet of the work we do in order to innovate and re-innovate the way vaccines are delivered. MODEL EXCELLENCE: The magnitude of our challenge requires our shared commitment to demonstrating integrity, accountability, equality and clarity across communications and decision making. \n",
       "\n",
       "Essential Functions:\n",
       "\n",
       "Assist in designing and executing process development runs focusing on scale down modeling and late-stage process characterization of upstream and primary recovery steps. Operate and maintain instrumentation including BSL2 microbial fermenters, TFF systems, depth filtration and centrifugation. Record data in electronic laboratory notebooks, and aid in writing technical summary reports. Perform analytical assays for process development and in-process manufacturing samples and maintain manufacturing and process development data repositories. Perform statistical analysis for manufacturing in-process data for manufacturing process insights and characterization purposes. Present data to the team to provide updates on small scale development activities and contribute to technical discussions. Perform scaling calculations between large scale manufacturing and small-scale process development operations. Review manufacturing documents and transfer in-process data to data repositories. \n",
       "\n",
       "Requirements:\n",
       "\n",
       "B.S./M.S. in bioengineering, chemical engineering, biochemistry or other related disciplines with 3+ years of experience. Prior experience with bioreactor fermentations, including glass and single use vessels, as well as experience with depth filtration, centrifugation, and TFF for primary recovery. Experience with analytical methods such as plate-based assays, UV-spectrophotometry, and metabolite analyzers. Experience writing technical documents including lab operation protocols and data summary reports. Proficiency in computer programs including Microsoft Excel, Word, and Powerpoint. Experience with statistical software such as JMP, R studio, python, etc. for manufacturing process analytics. Familiarity with statistical methods for process characterization and validation is a plus. Familiarity with DOE principles and experience with DoE software (JMP) is a plus. Some experience with GXP requirements including deviation investigations, CAPAs, and change controls. Understanding of engineering principles for scaling upstream unit operations. All Vaxcyte employees require vaccination against COVID-19. \n",
       "\n",
       "Reports to: MSAT Engineer II, Polysaccharide\n",
       "\n",
       "Location: San Carlos, CA\n",
       "\n",
       "Compensation:\n",
       "\n",
       "The compensation package will be competitive and includes comprehensive benefits and an equity component.\n",
       "\n",
       "Salary Range:  $107,000 – $123,000\n",
       "\n",
       "Send resumes to: \n",
       "\n",
       "careers@vaxcyte.com\n",
       "\n",
       "Vaxcyte, Inc.\n",
       "\n",
       "825 Industrial Road, Suite 300\n",
       "\n",
       "San Carlos, CA 94070\n",
       "\n",
       "We are an equal opportunity employer. All qualified applicants will receive consideration for employment without regard to race, color, religion, sex, sexual orientation, gender identity, national origin, disability or veteran status.</td><td>123000.0</td><td>YEARLY</td><td>San Carlos, CA</td><td>7603371.0</td><td>8.0</td><td>null</td><td>107000.0</td><td>Full-time</td><td>1.0</td><td>1.712370296E12</td><td>null</td><td>https://www.linkedin.com/jobs/view/3887873255/?trk=jobs_biz_prem_srch</td><td>https://jobs.lever.co/vaxcyte/101005b6-e786-45fe-b282-58c5acae1915/apply</td><td>OffsiteApply</td><td>1.714963102E12</td><td>null</td><td>Mid-Senior level</td><td>null</td><td>1.712371102E12</td><td>jobs.lever.co</td><td>0</td><td>FULL_TIME</td><td>USD</td><td>BASE_SALARY</td><td>115000.0</td><td>94070</td><td>6081</td></tr><tr><td>3891075905</td><td>Torch</td><td>Sr. Analytics Engineer</td><td>OUR MISSIONAt Torch, we believe in the power of people. People are the heart of every success story. They collaborate to achieve ambitious things together. And they inspire others to build a better future. \n",
       "That’s why our mission at Torch is to unlock the potential of people, teams, and organizations. We believe that trusted relationships are the key to helping people realize their full potential. When people experience transformational growth in the context of a trusted relationship, they achieve more, their teams excel, and their organizations thrive.\n",
       "By combining a community of expert coaches, scalable technology, and the latest behavioral science, Torch helps our customers develop their people, create stronger leaders and managers, and drive business performance. \n",
       "Backed by top-tier investors, Torch is a fast-growing, mission-driven SaaS startup comprised of people who are passionate about helping leaders, their teams, and their organizations achieve more. If that sounds worthwhile to you, join us. Torch is a remote and distributed team with an office in San Francisco. The rest of the team is scattered around the U.S.\n",
       "OUR VALUESAll Torch employees are expected to reflect and enhance our company values, GROWS:\n",
       "Go DeepWe study the science, learn from the best practitioners, and dig in with customers to solve their unique needs.Relationships MatterWe lean into relationships with empathy to create more meaningful connections and more meaningful impact.\n",
       "Own ItWe take responsibility for our commitments, our contributions, our results and for the success of those around us.\n",
       "Win TogetherWe believe that happiness and fulfillment at work comes from shared success and value.\n",
       "Sprint ForwardWe prioritize, sprint, learn, adjust, and then sprint again.\n",
       "THE TEAMThe Data & Analytics team at Torch is looking for an experienced Analytics Engineer who can uplevel our insights delivery reporting directly to the Senior Engineering Manager. In this role, you’ll have the opportunity to shape Torch’s data strategy and drive insights that inform product decisions across the company.\n",
       "YOUR ROLECollaborate with cross-functional stakeholders to understand business needs and deliver data products that enable smarter decision making.Identify and prioritize opportunities to improve data quality, data capture, accessibility and governance.Create data models that provide business visibility into metrics such as user engagement, growth, customer health and more.Share knowledge across teams, developing best practices and standards for analytics engineering and data warehousing.Automate processes to increase efficiency of data analysis across Torch.Manage our DBT implementation and develop new data models and pipelines.\n",
       "YOU HAVE5+ years of experience as an Analytics Engineer, Data Analyst or Data Engineer2+ years of experience with DBTExpertise with SQL, python and data modeling conceptsExperience with a modern business intelligence tool (Preset / Superset preferred)Familiarity with version control tools such as Git\n",
       "NICE TO HAVEExperience with orchestration and ingestion tools such as Airbyte, Dagster, Airflow and lambda functionsBackground or interest in AI and ML Data OpsBackground in statistics or data science\n",
       "BENEFITSHealth Insurance (medical, dental, and vision)Unlimited PTO401k Retirement PlanLife & Disability InsurancePaid Parental LeaveTorch CoachingUP Days (flexible Fridays)Remote Work Stipend\n",
       "Torch ensures equal employment opportunity without discrimination or harassment based on race, color, religion, sex (including pregnancy, childbirth, or related medical conditions), sexual orientation, gender identity or expression, age, disability, national origin, marital or domestic/civil partnership status, genetic information, citizenship status, veteran status, or any other characteristic protected by law.</td><td>150000.0</td><td>YEARLY</td><td>United States</td><td>1.8382984E7</td><td>3.0</td><td>null</td><td>110000.0</td><td>Full-time</td><td>null</td><td>1.712864598E12</td><td>1.0</td><td>https://www.linkedin.com/jobs/view/3891075905/?trk=jobs_biz_prem_srch</td><td>https://jobs.lever.co/torch/5a1e190f-3d43-4f9c-9651-fcf42e381f02</td><td>OffsiteApply</td><td>1.715456598E12</td><td>null</td><td>null</td><td>null</td><td>1.712864598E12</td><td>null</td><td>0</td><td>FULL_TIME</td><td>USD</td><td>BASE_SALARY</td><td>130000.0</td><td>null</td><td>null</td></tr><tr><td>3891081235</td><td>Flip</td><td>Integration Engineer</td><td>Join the Flip team: A social shopping app [network] redefining the online shopping experience. Born from the idea that shopping should be a communal, transparent, and enriching experience, Flip has quickly become the go-to platform for users who crave authenticity and connection in their shopping journey. At Flip, we believe in the power of real reviews, high-quality products, and a seamless shopping experience that transforms browsing into an engaging adventure. From discovery to checkout, Flip offers everything in one place, fostering a community where every purchase is a shared experience.\n",
       "The Opportunity: As Platform Integration Specialist, you will be a crucial member of the Platform Integrations & Support Team responsible for the overall health and performance of commerce platforms & connectors used by brands to onboard onto Flip. You are primarily responsible for root cause analysis, resolution and proactive monitoring to maintain Middleware reliability. This is a high growth potential role.\n",
       "Responsibilities\n",
       "Monitor daily processes and flow to identify issues and outages.Collaborate with brands and technology partners to understand and diagnose e-commerce integration challenges.Troubleshoot and resolve e-commerce integration issues in a timely manner.Collaborate with the engineering team to report common issues and suggest long-term solutions.Act as a primary point of contact for Platform Integration partners, reporting problems , providing training, and ensuring timely resolution.Timely escalate issues and prioritize.Develop and Automate monitoring and detection processesSupport in assessing new integration solutions.\n",
       "Requirements\n",
       "2 years experience managing e-commerce operations on storefront is highly preferred. Experience with python, efficiency in data structures and algorithms.Familiarity with e-commerce platforms.Excellent communication skills to liaise with brands and internal teams.A collaborative spirit and ability to work as part of a dynamic team.Proficient with excel formulas.\n",
       "$65,000 - $80,000 a yearBase salary and total compensation will vary based on factors including but not limited to location, experience, and performance. Please note the base salary is just one component of the company’s total rewards package for exempt employees. Other rewards may include equity, long term incentives, a PTO policy, and other progressive benefits.</td><td>80000.0</td><td>YEARLY</td><td>El Segundo, CA</td><td>1.5819562E7</td><td>3.0</td><td>null</td><td>65000.0</td><td>Full-time</td><td>1.0</td><td>1.712866099E12</td><td>null</td><td>https://www.linkedin.com/jobs/view/3891081235/?trk=jobs_biz_prem_srch</td><td>https://jobs.lever.co/flipfit/32700f0f-a57b-4642-9a97-5e6203b85ebf?source=6</td><td>OffsiteApply</td><td>1.715458099E12</td><td>null</td><td>Associate</td><td>null</td><td>1.712866099E12</td><td>null</td><td>0</td><td>FULL_TIME</td><td>USD</td><td>BASE_SALARY</td><td>72500.0</td><td>90245</td><td>6037</td></tr><tr><td>3894210251</td><td>AVEVA</td><td>Cloud Security Operations Developer</td><td>AVEVA is a global leader in industrial software. Our cutting-edge solutions are used by thousands of enterprises to deliver the essentials of life – such as energy, infrastructure, chemicals and minerals – safely, efficiently and more sustainably.\n",
       "\n",
       "We’re the first software business in the world to have our sustainability targets validated by the SBTi, and we’ve been recognized for the transparency and ambition of our commitment to diversity, equity, and inclusion. We’ve also recently been named as one of the world’s most innovative companies.\n",
       "\n",
       "If you’re a curious and collaborative person who wants to make a big impact through technology, then we want to hear from you! Find out more at https://www.aveva.com/en/about/careers/.\n",
       "\n",
       "Position: Cloud Security Operations Developer\n",
       "\n",
       "Qualifications:  Experience in researching and identifying new threats, vulnerabilities and risks for Cloud-native environments\n",
       "\n",
       "Location: Lake Forest, California – Hybrid \n",
       "\n",
       "Employment type: Full-time regular (flexible working options available)\n",
       "\n",
       "About the role:\n",
       "\n",
       "As part of the Research and Development function, the global Cloud DevOps team combines software development and cloud operations to provide continuous integration and delivery of cloud-enabled products and solutions.\n",
       "\n",
       "As a Security Software Developer (AWS & Azure), you will have the opportunity to join a new team whose responsibility is to:\n",
       "\n",
       "Pro-actively identify improvements to AVEVA’s Cloud securityDesign solutions to resolveCreate code to deliver these solutionsIdentify potential new threats to Aveva’s Cloud security Maintain strong working relationships with AVEVA’s Cloud Service Providers and internal development teams.Support, enhance and automate:The day-to-day security posture of AVEVA’s Cloud solutions.The landing zones and the global applications and services hosted within it.The security tools and frameworks implemented in AVEVA’s Cloud solution. \n",
       "Working closely with your development and portfolio colleagues, together you will bring new solutions to the cloud following a standard framework to ensure they are operationally secure, stable, and scalable.\n",
       "\n",
       "The global, 24x7 nature of the team means there may be a requirement for occasional work outside of the standard day and to be on call as part of a shared team rota.\n",
       "\n",
       "Responsibilities:\n",
       "\n",
       "As part of the security and platform team you will:Continuously improve security tooling and processes.Build code to support automation and manage cloud setup e.g. Azure Functions, AWS Lambdas, Scripts etc…Improve our cloud estate management processes and tooling.Update the IaC code base which describes the cloud configurationsMonitor and analyse security relevant logs, alerts and events associated with security incidents.Respond to security incidents as identified by users or security monitoring tools to mitigate threats.Execute standard operating procedures in response to any security relevant logs, alerts and events.Determine Root Cause Analysis for significant security incidents and report on overall security incident levels, which might include conducting forensic analysis.Execute incident test scenarios to prove and improve security handling processes.Providing support outside of core hours where required.Work with development teams to advise and contribute to improvements to security, cost management and cloud compliance.Stay current on security industry trends, tools and best practices.\n",
       "Minimum Qualifications:\n",
       "\n",
       "Experience of developing code to help automate / control the cloud environment in python / C#Experience of operating/building services in either AWS or Azure.Experience of cloud security management in either AWS or Azure.Experience of writing infrastructure as code in either cloud formation/ARM/TerraformStrong written, verbal and presentation skills, able to convey information clearly and concisely to technical and non-technical audiences.Attention to detail, diligent and tenacious.Excellent analysis and dissemination skills.High degree of personal motivation and ability to self-manage.Maintains and develops relevant industry and technology knowledge.Working within an Information Security accredited framework e.g. ISO27001, 27017/18.\n",
       "\n",
       "Desired Certification:\n",
       "\n",
       "Certifications in Azure and/or AWS e.g. AWS Solutions Architect, Solutions Architect for Azure.Security related certifications e.g. Microsoft’s Security Operations Analyst, AWS Certified Security Specialist, CCSP.\n",
       "\n",
       "Salary Range:\n",
       "\n",
       "$99,100.00 - $165,300.00\n",
       "\n",
       "This pay range represents the minimum and maximum compensation that the position offers, and final compensation can vary within the range depending on work location, job experience, skills, and relevant educational attainment and/or training.\n",
       "\n",
       "USA Benefits: Competitive salary; high quality healthcare; 401(k) with 6% employer match; FSA and supplemental insurance; paid parental leave; 20 days PTO with increase for time served; 7 days of sick time; 3 days paid volunteering; flexible lifestyle benefits (commuter plans, backup care, emergency leave and fitness/education reimbursement opportunities)\n",
       "\n",
       "AVEVA requires all successful applicants to undergo and pass a comprehensive background check before they start employment. Background checks will be conducted in accordance with local laws and may, subject to those laws, include proof of educational attainment, employment history verification, proof of work authorization, criminal records, identity verification, credit check. Certain positions dealing with sensitive and/or third party personal data may involve additional background check criteria.\n",
       "\n",
       "AVEVA is an Equal Opportunity Employer. We are committed to being an exemplary employer with an inclusive culture, developing a workplace environment where all our employees are treated with dignity and respect. We value diversity and the expertise that people from different backgrounds bring to our business.  AVEVA provides reasonable accommodation to applicants with disabilities where appropriate. If you need reasonable accommodation for any part of the application and hiring process, please notify AVEVA at recruitingaccommodations@aveva.com. Determinations on requests for reasonable accommodation will be made on a case-by-case basis. \n",
       "\n",
       "Come and join AVEVA to create the transformative technology that enables our customers to engineer a better world.</td><td>165300.0</td><td>YEARLY</td><td>Lake Forest, CA</td><td>14547.0</td><td>4.0</td><td>null</td><td>99100.0</td><td>Full-time</td><td>null</td><td>1.71285502E12</td><td>null</td><td>https://www.linkedin.com/jobs/view/3894210251/?trk=jobs_biz_prem_srch</td><td>https://aveva.wd3.myworkdayjobs.com/AVEVA_careers/job/Lake-Forest-California-United-States-of-America/R-D-Cloud-Security-and-Infrastructure-Operations-Analyst--Cloud-DevOps_R007257-1?source=LinkedIn</td><td>OffsiteApply</td><td>1.715447869E12</td><td>null</td><td>Entry level</td><td>null</td><td>1.712855869E12</td><td>aveva.wd3.myworkdayjobs.com</td><td>0</td><td>FULL_TIME</td><td>USD</td><td>BASE_SALARY</td><td>132200.0</td><td>92630</td><td>6059</td></tr><tr><td>3894895210</td><td>Haven Technologies</td><td>Cloud Security Lead</td><td>Haven Technologies has built deep capabilities in the life, annuity and disability insurance spaces. And now, our tech is your tech.\n",
       "The same purpose-built platform and expertise that have helped us delight customers, transform complex, advisor-driven businesses, and launch groundbreaking products with speed are available to everyone as a SaaS offering. Insurance carriers can use our advanced solutions for new business, in-force management and product development.\n",
       "But Haven Technologies is not just, well, all about technology. Our people and culture make our product. We believe magic happens when people have an opportunity to work with amazing colleagues and build things that matter.\n",
       "As a team made of dreamers, possibility-seekers and difference-makers, we are focused on taking on challenging problems to create simple, more accessible, and more customer centric solutions. We're located in New York's Midtown and in case you're wondering, yes, we provide free snacks. Cold brew too. If you're creative, professional and kind, we'd love to hear from you. Curious about what it’s like to work with us? Read about our culture and values here!\n",
       "Let’s change the future of life insurance. Together.\n",
       " ABOUT THIS ROLE: You will be joining a small, experienced Information Security team tasked with guiding and carrying out Haven Tech’s security agenda. You will be collaborating closely with your team, as well as working hand-in-hand with employees across the broader organization to ensure that security best practices are a standard part of the way our company operates. In addition to strong technical skills, this role will require out-of-the-box thinking and thoughtfulness about how and why you do what you do. The job will be varied and challenging, using the latest tools, techniques, and apps. The ideal candidate will require experience in SRE, with a security based mindset. WHAT YOU’LL DO: Design, implement, and manage robust security solutions using Zero-Trust principles.Conduct regular security assessments to ensure compliance with industry standards and regulatory requirements like HIPAA/ SOC2.Lead incident response efforts in the event of a security breach, including containment, investigation, and recovery. Document and report security incidents, providing recommendations for improvement.Implement and manage data protection mechanisms such as encryption, tokenization, and data masking to safeguard sensitive information.Design, implement and maintain network security architectures including firewalls, VPNs, and segregated networks to protect the cloud environment. Leverage Infrastructure as code (IaC) and other automation tools to deploy security measures at scale. Implement security as code practices to integrate into the CI/CD pipelines. Ensure security is baked into the infrastructure from the onset.Be a security advocate within the organization. Provide guidance and training to development teams on best practices for security. Stay abreast of the latest security features and threats to continuously improve the security posture. REQUIREMENTS: BS in Computer Science or Related5+ years experience in Security2+ years of Cloud engineering security/infrastructureExperience in deploying, supporting and building infrastructure for highly distributed and scalable systems living in AWS/AzureExpertise with IaaC (we use Terraform)Experience with ELK/OpenSearchExperience with kubernetes and containersScripting experience (preferable python, javascript)Experience in explaining complex problems and solutions to people Experience in investigating security issues in a large distributed cloud environmentMust be able to work out of the NYC office 2-3 days/weekAuthorized to work in the US with or without sponsorship PREFERRED: Wazuh(IDS)/ NIDS experienceAWS Security tooling (AWS Config, GuardDuty, WAF/FMS, Inspector, Macie, IAM)Zero Trust implementation exposureAPI Gateway, Secrets ManagementCIS Benchmarking experienceSecurity monitoring experienceAgile project management \n",
       "BENEFITS:We have a stellar team of co-workers, a really cool office, a flexible hybrid work schedule, and lots of fun activities. Oh yeah, and we pay competitive base salaries and we reward performance. Our salary structure is commensurate with experience. In addition, you will be eligible to participate in our comprehensive benefits program including medical insurance and 401(K).\n",
       "We believe that one of the benefits to working here is our people and culture! We’re proud to share that we’ve been consistently named a top workplace by Great Places to Work (#6 Best Workplaces in New York) and BuiltIn (Top 10 Best Midsize Companies to Work For in NYC)!Target annual salary for this role is $145,000 - $165,000 + a discretionary bonus opportunity + benefits (including medical, dental, vision, accident and life insurance, paid days off, 401(k), and education reimbursement).\n",
       "For California residents only: All information collected via this job notice is subject to Haven Tech’s California Privacy Rights Notice, located at https://www.haventech.us/california-privacy-rights-notice/.</td><td>165000.0</td><td>YEARLY</td><td>New York City Metropolitan Area</td><td>5339453.0</td><td>2.0</td><td>null</td><td>145000.0</td><td>Full-time</td><td>null</td><td>1.71285647E12</td><td>null</td><td>https://www.linkedin.com/jobs/view/3894895210/?trk=jobs_biz_prem_srch</td><td>https://boards.greenhouse.io/haventechus/jobs/7304222002</td><td>OffsiteApply</td><td>1.715448469E12</td><td>null</td><td>Mid-Senior level</td><td>null</td><td>1.71285647E12</td><td>null</td><td>0</td><td>FULL_TIME</td><td>USD</td><td>BASE_SALARY</td><td>155000.0</td><td>null</td><td>null</td></tr></tbody></table></div>"
      ]
     },
     "metadata": {
      "application/vnd.databricks.v1+output": {
       "addedWidgets": {},
       "aggData": [],
       "aggError": "",
       "aggOverflow": false,
       "aggSchema": [],
       "aggSeriesLimitReached": false,
       "aggType": "",
       "arguments": {},
       "columnCustomDisplayInfos": {},
       "data": [
        [
         3884822884,
         "Stanford University",
         "Research Data Analyst 1 (75% FTE/Hybrid Opportunity)",
         "The Department of Psychiatry and Behavioral Sciences at Stanford University’s School of Medicine is seeking Research Data Analyst (RDA 1) 1 to manage and analyze large amounts of multi-modality brain imaging data under the direction of Dr. Vankee Lin. CogT Lab focuses on the evaluation of various cognitive interventions among older adults and understanding the underlying neural mechanisms. For more information on the lab, please visit: https://www.cogtlab.com/\n\nThis position will be 75% FTE. Interested candidates should include a cover letter along with their CV.\n\nDuties Include\n\n Manage and clean datasets. Employ new and existing tools to interpret, analyze, and visualize multivariate relationships in data. Create databases and reports, develop algorithms and statistical and/or computational models, and perform data analyses appropriate to data and reporting requirements. Use system reports and analyses to identify potentially problematic data, make corrections, and determine root cause for data problems from input errors or inadequate field edits, and suggest possible solutions. Develop reports, charts, graphs and tables for use by investigators and for publication and presentation. Analyze data processes in documentation. Collaborate with faculty and research staff on data collection and analysis methods. Provide documentation based on audit and reporting criteria to investigators and research staff. Communicate with government officials, grant agencies and industry representatives.  - Other duties may also be assigned\n\n\nDesired Qualifications\n\nBachelor's degree in computational and engineering sciences (e.g., computer science, computational biology, electrical engineering, biomedical engineering) or other related fields. Experience with signal processing of medical imaging data. Experience with or demonstrated interest in neuroimaging techniques. Experience with Neuroimaging (FSL, SPM, AFNI, or equivalent) software. Experience using high-performance computer clusters and bash/shell scripting. Experience in data science, statistics, optimization, machine learning, and/or deep learning. Experience with machine learning frameworks (e.g. PyTorch, Tensorflow, etc.) Experience with Statistical software (R, SAS, SPSS, or equivalent), and other common programming languages in neuroimaging (python, MATLAB). Prior experience with R is highly recommended for data analysis. \n\n\nEducation & Experience (required)\n\n Bachelor's degree or a combination of education and relevant experience. Experience in a quantitative discipline such as economics, finance, statistics or engineering. \n\n\nKnowledge, Skills And Abilities (required)\n\nSubstantial experience with MS Office and analytical programs Strong writing and analytical skills in machine learning. Ability to prioritize workload. \n\n\nPHYSICAL REQUIREMENTS*:\n\n Sitting in place at computer for long periods of time with extensive keyboarding/dexterity. Occasionally use a telephone. Rarely writing by hand.  - Consistent with its obligations under the law, the University will provide reasonable accommodation to any employee with a disability who requires accommodation to perform the essential functions of his or her job.\n\n\nWorking Conditions\n\nSome work may be performed in a laboratory or field setting. This position is based in Stanford’s Research Park and has the option of a telecommuting/hybrid schedule subject to operational needs. This position is 75% FTE. \n\n\nThe expected pay range for this position is $48,360 to $72,750 per annum. Stanford University provides pay ranges representing its good faith estimate of what the university reasonably expects to pay for a position. The pay offered to a selected candidate will be determined based on factors such as (but not limited to) the scope and responsibilities of the position, the qualifications of the selected candidate, departmental budget availability, internal equity, geographic location and external market pay for comparable jobs.\n\n - Stanford is an equal employment opportunity and affirmative action employer. All qualified applicants will receive consideration for employment without regard to race, color, religion, sex, sexual orientation, gender identity, national origin, disability, protected veteran status, or any other characteristic protected by law",
         72750.0,
         "YEARLY",
         "Stanford, CA",
         1792.0,
         12.0,
         null,
         48360.0,
         "Part-time",
         1.0,
         1.712372056E12,
         null,
         "https://www.linkedin.com/jobs/view/3884822884/?trk=jobs_biz_prem_srch",
         "https://stanford.taleo.net/careersection/2/jobdetail.ftl?utm_medium=campaign&job=102822&lang=en&utm_source=linkedin",
         "OffsiteApply",
         1.714964771E12,
         null,
         "Mid-Senior level",
         null,
         1.712372771E12,
         "stanford.taleo.net",
         0,
         "PART_TIME",
         "USD",
         "BASE_SALARY",
         60555.0,
         94305,
         6085
        ],
        [
         3886150898,
         "Reworkd AI (YC S23)",
         "Founding Engineer",
         "About ReworkdAt Reworkd, we’re working on multi-modal LLM agents to extract structured web data at scale. Since inception, Reworkd has been one of the leaders in AI Agents, having built and scaled AgentGPT to over 1M+ monthly users.\nWe are a team of engineers and operators from leading CS universities such as UBC, CMU and SFU. Our team has prior experience at organizations such as AWS, Article and Microsoft. Currently a small, fast moving team of four, we’ve built every layer our our LLM/Agent stack including: evals, prompt design, LLM/Agent routing and custom OCR pipelines.\nAdditionally, we’re backed by top to tier investors including YCombinator, SV Angel, General Catalyst, Panache Ventures, and many more.\nAbout your role:As a founding backend engineer at Reworkd, you will help shape the future of LLM agents taking web actions. In your first month you may:Build a robust queuing system to handle 1M+ compute heavy (playwright) jobs a dayMigrate an existing pool of batch workers off of AWS to bare metalEnhance autoscaling / deployment strategy using K8s or similar technologiesGive our code generation agents additional superpowers (eg: captcha solving. crawling, etc…)\nResponsibilitiesLeading and collaborating on mission critical features / bugsPromoting engineering best practices throughout the rest of the teamEnsuring that our tech stack is able to scale with our hyper growth\nQualifications and Skills:Located in the bay area or able to relocate to the bay areaExpertise in writing production grade python (+typescript). Bonus if you have experience with NextJS, FastAPI, and SQLAlchemy/SQLModel.Prior experience building and managing distributed / batch job systemsProficiency with optimizing queries in MySQL, Postgres, or similar SQL based databaseExperienced with hosting on AWS and/or bare metal (knowledge of K8s is a plus)Prior experience as an operator or founding employee at another startupDeep knowledge of modern web automation techniques (eg: selenium, playwright, CDP protocol, proxies etc..)Ability to operate with a high sense of agency\nCompensation:The base compensation for this role is $130,000 - $170,000 USD per year. In addition, you will also receive equity-based compensation, a top tier medical / dental / vision plan, and unlimited PTO. In addition, we also host weekly team outings, team dinners and will even give you a haircut (no seriously, our COO is a barber).\nInterview Process:We like to keep interview loops short but want actual in person working sessions so each of us can determine if we’re the right fitFirst step: 30 min intro call with a founderSecond step: 1 hour call with founding team + pair programming sessionsThird step: Two paid weeks of in person work, this is your chance to make sure we are also a good fit for you.Decision: we'll get back to you within a week of the final interview.\nReworkd is committed to fostering and empowering an inclusive community within our organization. We do not discriminate on the basis of race, religion, color, gender expression or identity, sexual orientation, national origin, citizenship, age, marital status, veteran status, disability status, or any other characteristic protected by law. Reworkd encourages everyone to apply for our available positions, even if they don't necessarily check every box on the job description.\nReworkd is an in-person company, our brand new office is located in the heart of San Francisco. Successful candidates will be required to relocate if they do not already live in the bay area.",
         170000.0,
         "YEARLY",
         "San Francisco Bay Area",
         9.1361772E7,
         16.0,
         null,
         130000.0,
         "Full-time",
         2.0,
         1.712894808E12,
         null,
         "https://www.linkedin.com/jobs/view/3886150898/?trk=jobs_biz_prem_srch",
         null,
         "ComplexOnsiteApply",
         1.715486808E12,
         null,
         null,
         null,
         1.712894808E12,
         null,
         0,
         "FULL_TIME",
         "USD",
         "BASE_SALARY",
         150000.0,
         null,
         null
        ],
        [
         3886896623,
         "Ascendion",
         "Full Stack Developer",
         "About Ascendion:Ascendion is a full-service digital engineering solutions company. We make and manage software platforms and products that power growth and deliver captivating experiences to consumers and employees. Our engineering, cloud, data, experience design, and talent solution capabilities accelerate transformation and impact for enterprise clients. Headquartered in New Jersey, our workforce of 6,000+ Ascenders delivers solutions from around the globe. Ascendion is built differently to engineer the next. Ascendion | Engineering to elevate life\nWe have a culture built on opportunity, inclusion, and a spirit of partnership. Come, change the world with us:Build the coolest tech for world’s leading brandsSolve complex problems – and learn new skillsExperience the power of transforming digital engineering for Fortune 500 clientsMaster your craft with leading training programs and hands-on experience\nExperience a community of change makers!Join a culture of high-performing innovators with endless ideas and a passion for tech. Our culture is the fabric of our company, and it is what makes us unique and diverse. The way we share ideas, learning, experiences, successes, and joy allows everyone to be their best at Ascendion.\nAbout the Role:Job Title: Full Stack Developer\nLocation: Chicago, IL/Houston, TX (Hybrid)\nKey Responsibilities:The Full stack Developer will advance the develop and deliver quality solutions using Node.js, HTTP, REST, NoSQL, and other web technologies.Work with minimum technical supervision and supplemental engineering support.Design and develop enhancements on new and existing applications using Node.js.Proficient understanding of code versioning tools, such as Git/SVN.\nMinimum Qualifications:Bachelor's Degree and three years of work experience, or in lieu of a Bachelor's5+ years of experience with Node JS developing APIs (must have), and nice to have knowledge of python, and/or other scripting languages, express.js, next.js5 years’ experience implementing AWS technologies.Experience with Cloud Automation Development Tool such as Git, Python/Bash/PowerShell ScriptingHands-on development and proficient excellence in backend API development using Node.js.Expertise in building REST-based microservices in a serverless architecture.Experience and thorough understanding of NoSQL databases like DynamoDB.Familiarity with event/message-driven system design and architecture.Experience writing tests and executing them using Node Lambda.Experience in agile environmentOral and written communication skills\nSalary Range: The salary for this position is between $100,000 – $115,000 annually. Factors which may affect pay within this range may include geography/market, skills, education, experience, and other qualifications of the successful candidate.\nThis position is eligible for commissions in accordance with the terms of the Company’s plan. Commissions for this position are estimated to be based on individual performance. Additionally, this role is also eligible for bonus based on achievement of mutually agreed KRAs.\nBenefits: The Company offers the following benefits for this position, subject to applicable eligibility requirements: [medical insurance] [dental insurance] [vision insurance] [401(k) retirement plan] [long-term disability insurance] [short-term disability insurance] [personal days accrued each calendar year. The Paid time off benefits meet the paid sick and safe time laws that pertains to the City/ State] [12-15 days of paid vacation time] [6-8 weeks of paid parental leave after a year of service] [9 paid holidays and 2 floating holidays per calendar year] [Ascendion Learning Management System] [Tuition Reimbursement Program]\nWant to change the world? Let us know.Tell us about your experiences, education, and ambitions. Bring your knowledge, unique viewpoint, and creativity to the table. Let’s talk!",
         115000.0,
         "YEARLY",
         "Chicago, IL",
         8.669468E7,
         200.0,
         null,
         100000.0,
         "Full-time",
         83.0,
         1.712668075E12,
         null,
         "https://www.linkedin.com/jobs/view/3886896623/?trk=jobs_biz_prem_srch",
         null,
         "ComplexOnsiteApply",
         1.715260075E12,
         null,
         "Mid-Senior level",
         null,
         1.712668075E12,
         null,
         0,
         "FULL_TIME",
         "USD",
         "BASE_SALARY",
         107500.0,
         60601,
         17031
        ],
        [
         3886964478,
         "Cornerstone Defense",
         "Network Engineer (Clearance Required) ",
         "Network EngineerSunnyvale, CAActive Secret or Top SecretJob Responsibilities:Network hardware & software expertise in support of the Combined Orbital Operations Logistics and Resiliency (COOLR)contract on Factory AEHF System Database (ASDB), Flight Software (FSW) and Network AEHF System Testbed - Tools (NAST-T) activities.existing Network & NetApp Filer configurations and practices, and recommend refinements, improvements, and performance enhancements to align with industry best practices and Security compliance requirements.administration, system backups and troubleshooting the Network (Windows/Unix/LINUX) servers and NetApp filer storage array.Required Skills:IT administration including experience with installation, configuration, and maintenance of Windows/UNIX/LINUX servers and network IT infrastructure.with maintaining Oracle database servers.with of networked database server and NetApp filers.with developing and debugging related scripts in UNIX shell scripting languages, Perl, or python.understanding of software and database development processes.",
         150000.0,
         "YEARLY",
         "Sunnyvale, CA",
         3772194.0,
         6.0,
         null,
         130000.0,
         "Full-time",
         null,
         1.713460223E12,
         null,
         "https://www.linkedin.com/jobs/view/3886964478/?trk=jobs_biz_prem_srch",
         null,
         "ComplexOnsiteApply",
         1.716052223E12,
         null,
         null,
         null,
         1.713460223E12,
         null,
         0,
         "FULL_TIME",
         "USD",
         "BASE_SALARY",
         140000.0,
         94085,
         null
        ],
        [
         3887716794,
         "Kavaliro",
         "Electrical Engineer",
         "Kavaliro is seeking an Electrical Engineer for an innovative company focused on research and development with a substantial concentration on hydrogen within the renewable energy sector. We leverage intellectual property with cutting-edge technology and materials to create novel solutions for many challenges the energy industry is facing today and will face in the future. With a multidisciplinary structure in an environment focused on collaboration, we value employee professional development in parallel with company success. If you are interested in working with a passionate engineering team to achieve groundbreaking value, we invite you to apply.\n \n \n \n Roles and Responsibilities:\n \n - Design electrical and automated control systems, AC and DC power systems, and electromechanical systems in a manufacturing process.\n \n - Integrate components including digital and analog sensors, communication devices, AC and DC motors, and heating elements.\n \n - Troubleshoot I/O connections, wiring, program logic, and power systems.\n \n - Purchase components and manage vendor relationships.\n \n - Develop software to test and operate systems in ladder logic and on other development platforms.\n \n - Create schematics for designs.\n \n - Communicate and present designs and results to a cross-functional engineering team.\n \n - Provide feedback on system level designs.\n \n \n \n \nRequirements:\n \n - Bachelor’s degree in Electrical Engineering.\n \n - Experience in circuit design, component selection, integration, and testing.\n \n - Experience with wiring low-voltage controls components and circuits.\n \n - Experience with PLC’s.\n \n - Programming experience in ladder logic, python, C, or related language.\n \n - Understanding of core electrical concepts related to controls systems.\n \n - Understanding of different motor types and applications.\n \n - Proficient with hand and power tool operation and safety.\n \n - CAD experience.\n \n \n \n\nKavaliro provides Equal Employment Opportunities to all employees and applicants. All qualified applicants will receive consideration for employment without regard to race, color, religion, age, sex, national origin, disability status, genetics, protected veteran status, sexual orientation, gender identity or expression, or any other characteristic protected by federal, state, or local laws. Kavaliro is committed to the full inclusion of all qualified individuals. In keeping with our commitment, Kavaliro will take steps to assure that people with disabilities are provided reasonable accommodations. Accordingly, if reasonable accommodation is required to fully participate in the job application or interview process, to perform the essential functions of the position, and/or to receive all other benefits and privileges of employment, please respond to this posting to connect with a company representative.",
         85000.0,
         "YEARLY",
         "Jacksonville, FL",
         1070686.0,
         13.0,
         null,
         75000.0,
         "Full-time",
         1.0,
         1.712350491E12,
         null,
         "https://www.linkedin.com/jobs/view/3887716794/?trk=jobs_biz_prem_srch",
         "https://www.aptrack.co/uap/AAAGoQAPjHwCPYFP/",
         "OffsiteApply",
         1.7149422E12,
         null,
         "Mid-Senior level",
         null,
         1.712350491E12,
         "www.aptrack.co",
         0,
         "FULL_TIME",
         "USD",
         "BASE_SALARY",
         80000.0,
         32099,
         12031
        ],
        [
         3887873255,
         "Vaxcyte",
         "Sr. Associate Engineer, Polysaccharide Process Development",
         "Join our Mission to Protect Humankind!\n\nVaxcyte is a clinical-stage vaccine innovation company engineering high-fidelity vaccines to protect humankind from the consequences of bacterial diseases, which have serious and costly health consequences when left unchecked. Working to eradicate or treat bacterial infections such as invasive pneumococcal disease, Group A Strep, periodontitis and Shigella is just the beginning. Our path to success is clear and well-defined, and Vaxcyte is set up to go the distance.\n\nWHAT we do is every bit as important as HOW we do it! Our work together is guided by four enduring core values:\n\nAIM HIGH: We embody our collectively audacious goal to courageously make the most complex biologics ever attempted to protect humankind. LEAD WITH HEART: Everyone leads at Vaxcyte with a kindness-first, inclusive approach to collaboration and vigorous debate that advances our business objectives. RETHINK CONVENTION: We bring creative and intellectual diversity to every facet of the work we do in order to innovate and re-innovate the way vaccines are delivered. MODEL EXCELLENCE: The magnitude of our challenge requires our shared commitment to demonstrating integrity, accountability, equality and clarity across communications and decision making. \n\nEssential Functions:\n\nAssist in designing and executing process development runs focusing on scale down modeling and late-stage process characterization of upstream and primary recovery steps. Operate and maintain instrumentation including BSL2 microbial fermenters, TFF systems, depth filtration and centrifugation. Record data in electronic laboratory notebooks, and aid in writing technical summary reports. Perform analytical assays for process development and in-process manufacturing samples and maintain manufacturing and process development data repositories. Perform statistical analysis for manufacturing in-process data for manufacturing process insights and characterization purposes. Present data to the team to provide updates on small scale development activities and contribute to technical discussions. Perform scaling calculations between large scale manufacturing and small-scale process development operations. Review manufacturing documents and transfer in-process data to data repositories. \n\nRequirements:\n\nB.S./M.S. in bioengineering, chemical engineering, biochemistry or other related disciplines with 3+ years of experience. Prior experience with bioreactor fermentations, including glass and single use vessels, as well as experience with depth filtration, centrifugation, and TFF for primary recovery. Experience with analytical methods such as plate-based assays, UV-spectrophotometry, and metabolite analyzers. Experience writing technical documents including lab operation protocols and data summary reports. Proficiency in computer programs including Microsoft Excel, Word, and Powerpoint. Experience with statistical software such as JMP, R studio, python, etc. for manufacturing process analytics. Familiarity with statistical methods for process characterization and validation is a plus. Familiarity with DOE principles and experience with DoE software (JMP) is a plus. Some experience with GXP requirements including deviation investigations, CAPAs, and change controls. Understanding of engineering principles for scaling upstream unit operations. All Vaxcyte employees require vaccination against COVID-19. \n\nReports to: MSAT Engineer II, Polysaccharide\n\nLocation: San Carlos, CA\n\nCompensation:\n\nThe compensation package will be competitive and includes comprehensive benefits and an equity component.\n\nSalary Range:  $107,000 – $123,000\n\nSend resumes to: \n\ncareers@vaxcyte.com\n\nVaxcyte, Inc.\n\n825 Industrial Road, Suite 300\n\nSan Carlos, CA 94070\n\nWe are an equal opportunity employer. All qualified applicants will receive consideration for employment without regard to race, color, religion, sex, sexual orientation, gender identity, national origin, disability or veteran status.",
         123000.0,
         "YEARLY",
         "San Carlos, CA",
         7603371.0,
         8.0,
         null,
         107000.0,
         "Full-time",
         1.0,
         1.712370296E12,
         null,
         "https://www.linkedin.com/jobs/view/3887873255/?trk=jobs_biz_prem_srch",
         "https://jobs.lever.co/vaxcyte/101005b6-e786-45fe-b282-58c5acae1915/apply",
         "OffsiteApply",
         1.714963102E12,
         null,
         "Mid-Senior level",
         null,
         1.712371102E12,
         "jobs.lever.co",
         0,
         "FULL_TIME",
         "USD",
         "BASE_SALARY",
         115000.0,
         94070,
         6081
        ],
        [
         3891075905,
         "Torch",
         "Sr. Analytics Engineer",
         "OUR MISSIONAt Torch, we believe in the power of people. People are the heart of every success story. They collaborate to achieve ambitious things together. And they inspire others to build a better future. \nThat’s why our mission at Torch is to unlock the potential of people, teams, and organizations. We believe that trusted relationships are the key to helping people realize their full potential. When people experience transformational growth in the context of a trusted relationship, they achieve more, their teams excel, and their organizations thrive.\nBy combining a community of expert coaches, scalable technology, and the latest behavioral science, Torch helps our customers develop their people, create stronger leaders and managers, and drive business performance. \nBacked by top-tier investors, Torch is a fast-growing, mission-driven SaaS startup comprised of people who are passionate about helping leaders, their teams, and their organizations achieve more. If that sounds worthwhile to you, join us. Torch is a remote and distributed team with an office in San Francisco. The rest of the team is scattered around the U.S.\nOUR VALUESAll Torch employees are expected to reflect and enhance our company values, GROWS:\nGo DeepWe study the science, learn from the best practitioners, and dig in with customers to solve their unique needs.Relationships MatterWe lean into relationships with empathy to create more meaningful connections and more meaningful impact.\nOwn ItWe take responsibility for our commitments, our contributions, our results and for the success of those around us.\nWin TogetherWe believe that happiness and fulfillment at work comes from shared success and value.\nSprint ForwardWe prioritize, sprint, learn, adjust, and then sprint again.\nTHE TEAMThe Data & Analytics team at Torch is looking for an experienced Analytics Engineer who can uplevel our insights delivery reporting directly to the Senior Engineering Manager. In this role, you’ll have the opportunity to shape Torch’s data strategy and drive insights that inform product decisions across the company.\nYOUR ROLECollaborate with cross-functional stakeholders to understand business needs and deliver data products that enable smarter decision making.Identify and prioritize opportunities to improve data quality, data capture, accessibility and governance.Create data models that provide business visibility into metrics such as user engagement, growth, customer health and more.Share knowledge across teams, developing best practices and standards for analytics engineering and data warehousing.Automate processes to increase efficiency of data analysis across Torch.Manage our DBT implementation and develop new data models and pipelines.\nYOU HAVE5+ years of experience as an Analytics Engineer, Data Analyst or Data Engineer2+ years of experience with DBTExpertise with SQL, python and data modeling conceptsExperience with a modern business intelligence tool (Preset / Superset preferred)Familiarity with version control tools such as Git\nNICE TO HAVEExperience with orchestration and ingestion tools such as Airbyte, Dagster, Airflow and lambda functionsBackground or interest in AI and ML Data OpsBackground in statistics or data science\nBENEFITSHealth Insurance (medical, dental, and vision)Unlimited PTO401k Retirement PlanLife & Disability InsurancePaid Parental LeaveTorch CoachingUP Days (flexible Fridays)Remote Work Stipend\nTorch ensures equal employment opportunity without discrimination or harassment based on race, color, religion, sex (including pregnancy, childbirth, or related medical conditions), sexual orientation, gender identity or expression, age, disability, national origin, marital or domestic/civil partnership status, genetic information, citizenship status, veteran status, or any other characteristic protected by law.",
         150000.0,
         "YEARLY",
         "United States",
         1.8382984E7,
         3.0,
         null,
         110000.0,
         "Full-time",
         null,
         1.712864598E12,
         1.0,
         "https://www.linkedin.com/jobs/view/3891075905/?trk=jobs_biz_prem_srch",
         "https://jobs.lever.co/torch/5a1e190f-3d43-4f9c-9651-fcf42e381f02",
         "OffsiteApply",
         1.715456598E12,
         null,
         null,
         null,
         1.712864598E12,
         null,
         0,
         "FULL_TIME",
         "USD",
         "BASE_SALARY",
         130000.0,
         null,
         null
        ],
        [
         3891081235,
         "Flip",
         "Integration Engineer",
         "Join the Flip team: A social shopping app [network] redefining the online shopping experience. Born from the idea that shopping should be a communal, transparent, and enriching experience, Flip has quickly become the go-to platform for users who crave authenticity and connection in their shopping journey. At Flip, we believe in the power of real reviews, high-quality products, and a seamless shopping experience that transforms browsing into an engaging adventure. From discovery to checkout, Flip offers everything in one place, fostering a community where every purchase is a shared experience.\nThe Opportunity: As Platform Integration Specialist, you will be a crucial member of the Platform Integrations & Support Team responsible for the overall health and performance of commerce platforms & connectors used by brands to onboard onto Flip. You are primarily responsible for root cause analysis, resolution and proactive monitoring to maintain Middleware reliability. This is a high growth potential role.\nResponsibilities\nMonitor daily processes and flow to identify issues and outages.Collaborate with brands and technology partners to understand and diagnose e-commerce integration challenges.Troubleshoot and resolve e-commerce integration issues in a timely manner.Collaborate with the engineering team to report common issues and suggest long-term solutions.Act as a primary point of contact for Platform Integration partners, reporting problems , providing training, and ensuring timely resolution.Timely escalate issues and prioritize.Develop and Automate monitoring and detection processesSupport in assessing new integration solutions.\nRequirements\n2 years experience managing e-commerce operations on storefront is highly preferred. Experience with python, efficiency in data structures and algorithms.Familiarity with e-commerce platforms.Excellent communication skills to liaise with brands and internal teams.A collaborative spirit and ability to work as part of a dynamic team.Proficient with excel formulas.\n$65,000 - $80,000 a yearBase salary and total compensation will vary based on factors including but not limited to location, experience, and performance. Please note the base salary is just one component of the company’s total rewards package for exempt employees. Other rewards may include equity, long term incentives, a PTO policy, and other progressive benefits.",
         80000.0,
         "YEARLY",
         "El Segundo, CA",
         1.5819562E7,
         3.0,
         null,
         65000.0,
         "Full-time",
         1.0,
         1.712866099E12,
         null,
         "https://www.linkedin.com/jobs/view/3891081235/?trk=jobs_biz_prem_srch",
         "https://jobs.lever.co/flipfit/32700f0f-a57b-4642-9a97-5e6203b85ebf?source=6",
         "OffsiteApply",
         1.715458099E12,
         null,
         "Associate",
         null,
         1.712866099E12,
         null,
         0,
         "FULL_TIME",
         "USD",
         "BASE_SALARY",
         72500.0,
         90245,
         6037
        ],
        [
         3894210251,
         "AVEVA",
         "Cloud Security Operations Developer",
         "AVEVA is a global leader in industrial software. Our cutting-edge solutions are used by thousands of enterprises to deliver the essentials of life – such as energy, infrastructure, chemicals and minerals – safely, efficiently and more sustainably.\n\nWe’re the first software business in the world to have our sustainability targets validated by the SBTi, and we’ve been recognized for the transparency and ambition of our commitment to diversity, equity, and inclusion. We’ve also recently been named as one of the world’s most innovative companies.\n\nIf you’re a curious and collaborative person who wants to make a big impact through technology, then we want to hear from you! Find out more at https://www.aveva.com/en/about/careers/.\n\nPosition: Cloud Security Operations Developer\n\nQualifications:  Experience in researching and identifying new threats, vulnerabilities and risks for Cloud-native environments\n\nLocation: Lake Forest, California – Hybrid \n\nEmployment type: Full-time regular (flexible working options available)\n\nAbout the role:\n\nAs part of the Research and Development function, the global Cloud DevOps team combines software development and cloud operations to provide continuous integration and delivery of cloud-enabled products and solutions.\n\nAs a Security Software Developer (AWS & Azure), you will have the opportunity to join a new team whose responsibility is to:\n\nPro-actively identify improvements to AVEVA’s Cloud securityDesign solutions to resolveCreate code to deliver these solutionsIdentify potential new threats to Aveva’s Cloud security Maintain strong working relationships with AVEVA’s Cloud Service Providers and internal development teams.Support, enhance and automate:The day-to-day security posture of AVEVA’s Cloud solutions.The landing zones and the global applications and services hosted within it.The security tools and frameworks implemented in AVEVA’s Cloud solution. \nWorking closely with your development and portfolio colleagues, together you will bring new solutions to the cloud following a standard framework to ensure they are operationally secure, stable, and scalable.\n\nThe global, 24x7 nature of the team means there may be a requirement for occasional work outside of the standard day and to be on call as part of a shared team rota.\n\nResponsibilities:\n\nAs part of the security and platform team you will:Continuously improve security tooling and processes.Build code to support automation and manage cloud setup e.g. Azure Functions, AWS Lambdas, Scripts etc…Improve our cloud estate management processes and tooling.Update the IaC code base which describes the cloud configurationsMonitor and analyse security relevant logs, alerts and events associated with security incidents.Respond to security incidents as identified by users or security monitoring tools to mitigate threats.Execute standard operating procedures in response to any security relevant logs, alerts and events.Determine Root Cause Analysis for significant security incidents and report on overall security incident levels, which might include conducting forensic analysis.Execute incident test scenarios to prove and improve security handling processes.Providing support outside of core hours where required.Work with development teams to advise and contribute to improvements to security, cost management and cloud compliance.Stay current on security industry trends, tools and best practices.\nMinimum Qualifications:\n\nExperience of developing code to help automate / control the cloud environment in python / C#Experience of operating/building services in either AWS or Azure.Experience of cloud security management in either AWS or Azure.Experience of writing infrastructure as code in either cloud formation/ARM/TerraformStrong written, verbal and presentation skills, able to convey information clearly and concisely to technical and non-technical audiences.Attention to detail, diligent and tenacious.Excellent analysis and dissemination skills.High degree of personal motivation and ability to self-manage.Maintains and develops relevant industry and technology knowledge.Working within an Information Security accredited framework e.g. ISO27001, 27017/18.\n\nDesired Certification:\n\nCertifications in Azure and/or AWS e.g. AWS Solutions Architect, Solutions Architect for Azure.Security related certifications e.g. Microsoft’s Security Operations Analyst, AWS Certified Security Specialist, CCSP.\n\nSalary Range:\n\n$99,100.00 - $165,300.00\n\nThis pay range represents the minimum and maximum compensation that the position offers, and final compensation can vary within the range depending on work location, job experience, skills, and relevant educational attainment and/or training.\n\nUSA Benefits: Competitive salary; high quality healthcare; 401(k) with 6% employer match; FSA and supplemental insurance; paid parental leave; 20 days PTO with increase for time served; 7 days of sick time; 3 days paid volunteering; flexible lifestyle benefits (commuter plans, backup care, emergency leave and fitness/education reimbursement opportunities)\n\nAVEVA requires all successful applicants to undergo and pass a comprehensive background check before they start employment. Background checks will be conducted in accordance with local laws and may, subject to those laws, include proof of educational attainment, employment history verification, proof of work authorization, criminal records, identity verification, credit check. Certain positions dealing with sensitive and/or third party personal data may involve additional background check criteria.\n\nAVEVA is an Equal Opportunity Employer. We are committed to being an exemplary employer with an inclusive culture, developing a workplace environment where all our employees are treated with dignity and respect. We value diversity and the expertise that people from different backgrounds bring to our business.  AVEVA provides reasonable accommodation to applicants with disabilities where appropriate. If you need reasonable accommodation for any part of the application and hiring process, please notify AVEVA at recruitingaccommodations@aveva.com. Determinations on requests for reasonable accommodation will be made on a case-by-case basis. \n\nCome and join AVEVA to create the transformative technology that enables our customers to engineer a better world.",
         165300.0,
         "YEARLY",
         "Lake Forest, CA",
         14547.0,
         4.0,
         null,
         99100.0,
         "Full-time",
         null,
         1.71285502E12,
         null,
         "https://www.linkedin.com/jobs/view/3894210251/?trk=jobs_biz_prem_srch",
         "https://aveva.wd3.myworkdayjobs.com/AVEVA_careers/job/Lake-Forest-California-United-States-of-America/R-D-Cloud-Security-and-Infrastructure-Operations-Analyst--Cloud-DevOps_R007257-1?source=LinkedIn",
         "OffsiteApply",
         1.715447869E12,
         null,
         "Entry level",
         null,
         1.712855869E12,
         "aveva.wd3.myworkdayjobs.com",
         0,
         "FULL_TIME",
         "USD",
         "BASE_SALARY",
         132200.0,
         92630,
         6059
        ],
        [
         3894895210,
         "Haven Technologies",
         "Cloud Security Lead",
         "Haven Technologies has built deep capabilities in the life, annuity and disability insurance spaces. And now, our tech is your tech.\nThe same purpose-built platform and expertise that have helped us delight customers, transform complex, advisor-driven businesses, and launch groundbreaking products with speed are available to everyone as a SaaS offering. Insurance carriers can use our advanced solutions for new business, in-force management and product development.\nBut Haven Technologies is not just, well, all about technology. Our people and culture make our product. We believe magic happens when people have an opportunity to work with amazing colleagues and build things that matter.\nAs a team made of dreamers, possibility-seekers and difference-makers, we are focused on taking on challenging problems to create simple, more accessible, and more customer centric solutions. We're located in New York's Midtown and in case you're wondering, yes, we provide free snacks. Cold brew too. If you're creative, professional and kind, we'd love to hear from you. Curious about what it’s like to work with us? Read about our culture and values here!\nLet’s change the future of life insurance. Together.\n ABOUT THIS ROLE: You will be joining a small, experienced Information Security team tasked with guiding and carrying out Haven Tech’s security agenda. You will be collaborating closely with your team, as well as working hand-in-hand with employees across the broader organization to ensure that security best practices are a standard part of the way our company operates. In addition to strong technical skills, this role will require out-of-the-box thinking and thoughtfulness about how and why you do what you do. The job will be varied and challenging, using the latest tools, techniques, and apps. The ideal candidate will require experience in SRE, with a security based mindset. WHAT YOU’LL DO: Design, implement, and manage robust security solutions using Zero-Trust principles.Conduct regular security assessments to ensure compliance with industry standards and regulatory requirements like HIPAA/ SOC2.Lead incident response efforts in the event of a security breach, including containment, investigation, and recovery. Document and report security incidents, providing recommendations for improvement.Implement and manage data protection mechanisms such as encryption, tokenization, and data masking to safeguard sensitive information.Design, implement and maintain network security architectures including firewalls, VPNs, and segregated networks to protect the cloud environment. Leverage Infrastructure as code (IaC) and other automation tools to deploy security measures at scale. Implement security as code practices to integrate into the CI/CD pipelines. Ensure security is baked into the infrastructure from the onset.Be a security advocate within the organization. Provide guidance and training to development teams on best practices for security. Stay abreast of the latest security features and threats to continuously improve the security posture. REQUIREMENTS: BS in Computer Science or Related5+ years experience in Security2+ years of Cloud engineering security/infrastructureExperience in deploying, supporting and building infrastructure for highly distributed and scalable systems living in AWS/AzureExpertise with IaaC (we use Terraform)Experience with ELK/OpenSearchExperience with kubernetes and containersScripting experience (preferable python, javascript)Experience in explaining complex problems and solutions to people Experience in investigating security issues in a large distributed cloud environmentMust be able to work out of the NYC office 2-3 days/weekAuthorized to work in the US with or without sponsorship PREFERRED: Wazuh(IDS)/ NIDS experienceAWS Security tooling (AWS Config, GuardDuty, WAF/FMS, Inspector, Macie, IAM)Zero Trust implementation exposureAPI Gateway, Secrets ManagementCIS Benchmarking experienceSecurity monitoring experienceAgile project management \nBENEFITS:We have a stellar team of co-workers, a really cool office, a flexible hybrid work schedule, and lots of fun activities. Oh yeah, and we pay competitive base salaries and we reward performance. Our salary structure is commensurate with experience. In addition, you will be eligible to participate in our comprehensive benefits program including medical insurance and 401(K).\nWe believe that one of the benefits to working here is our people and culture! We’re proud to share that we’ve been consistently named a top workplace by Great Places to Work (#6 Best Workplaces in New York) and BuiltIn (Top 10 Best Midsize Companies to Work For in NYC)!Target annual salary for this role is $145,000 - $165,000 + a discretionary bonus opportunity + benefits (including medical, dental, vision, accident and life insurance, paid days off, 401(k), and education reimbursement).\nFor California residents only: All information collected via this job notice is subject to Haven Tech’s California Privacy Rights Notice, located at https://www.haventech.us/california-privacy-rights-notice/.",
         165000.0,
         "YEARLY",
         "New York City Metropolitan Area",
         5339453.0,
         2.0,
         null,
         145000.0,
         "Full-time",
         null,
         1.71285647E12,
         null,
         "https://www.linkedin.com/jobs/view/3894895210/?trk=jobs_biz_prem_srch",
         "https://boards.greenhouse.io/haventechus/jobs/7304222002",
         "OffsiteApply",
         1.715448469E12,
         null,
         "Mid-Senior level",
         null,
         1.71285647E12,
         null,
         0,
         "FULL_TIME",
         "USD",
         "BASE_SALARY",
         155000.0,
         null,
         null
        ]
       ],
       "datasetInfos": [
        {
         "name": "_sqldf",
         "schema": {
          "fields": [
           {
            "metadata": {},
            "name": "job_id",
            "nullable": true,
            "type": "long"
           },
           {
            "metadata": {},
            "name": "company_name",
            "nullable": true,
            "type": "string"
           },
           {
            "metadata": {},
            "name": "title",
            "nullable": true,
            "type": "string"
           },
           {
            "metadata": {},
            "name": "description",
            "nullable": true,
            "type": "string"
           },
           {
            "metadata": {},
            "name": "max_salary",
            "nullable": true,
            "type": "double"
           },
           {
            "metadata": {},
            "name": "pay_period",
            "nullable": true,
            "type": "string"
           },
           {
            "metadata": {},
            "name": "location",
            "nullable": true,
            "type": "string"
           },
           {
            "metadata": {},
            "name": "company_id",
            "nullable": true,
            "type": "double"
           },
           {
            "metadata": {},
            "name": "views",
            "nullable": true,
            "type": "double"
           },
           {
            "metadata": {},
            "name": "med_salary",
            "nullable": true,
            "type": "double"
           },
           {
            "metadata": {},
            "name": "min_salary",
            "nullable": true,
            "type": "double"
           },
           {
            "metadata": {},
            "name": "formatted_work_type",
            "nullable": true,
            "type": "string"
           },
           {
            "metadata": {},
            "name": "applies",
            "nullable": true,
            "type": "double"
           },
           {
            "metadata": {},
            "name": "original_listed_time",
            "nullable": true,
            "type": "double"
           },
           {
            "metadata": {},
            "name": "remote_allowed",
            "nullable": true,
            "type": "double"
           },
           {
            "metadata": {},
            "name": "job_posting_url",
            "nullable": true,
            "type": "string"
           },
           {
            "metadata": {},
            "name": "application_url",
            "nullable": true,
            "type": "string"
           },
           {
            "metadata": {},
            "name": "application_type",
            "nullable": true,
            "type": "string"
           },
           {
            "metadata": {},
            "name": "expiry",
            "nullable": true,
            "type": "double"
           },
           {
            "metadata": {},
            "name": "closed_time",
            "nullable": true,
            "type": "double"
           },
           {
            "metadata": {},
            "name": "formatted_experience_level",
            "nullable": true,
            "type": "string"
           },
           {
            "metadata": {},
            "name": "skills_desc",
            "nullable": true,
            "type": "string"
           },
           {
            "metadata": {},
            "name": "listed_time",
            "nullable": true,
            "type": "double"
           },
           {
            "metadata": {},
            "name": "posting_domain",
            "nullable": true,
            "type": "string"
           },
           {
            "metadata": {},
            "name": "sponsored",
            "nullable": true,
            "type": "long"
           },
           {
            "metadata": {},
            "name": "work_type",
            "nullable": true,
            "type": "string"
           },
           {
            "metadata": {},
            "name": "currency",
            "nullable": true,
            "type": "string"
           },
           {
            "metadata": {},
            "name": "compensation_type",
            "nullable": true,
            "type": "string"
           },
           {
            "metadata": {},
            "name": "normalized_salary",
            "nullable": true,
            "type": "double"
           },
           {
            "metadata": {},
            "name": "zip_code",
            "nullable": true,
            "type": "long"
           },
           {
            "metadata": {},
            "name": "fips",
            "nullable": true,
            "type": "long"
           }
          ],
          "type": "struct"
         },
         "tableIdentifier": null,
         "typeStr": "pyspark.sql.connect.dataframe.DataFrame"
        }
       ],
       "dbfsResultPath": null,
       "isJsonSchema": true,
       "metadata": {
        "createTempViewForImplicitDf": true,
        "dataframeName": "_sqldf",
        "executionCount": 152
       },
       "overflow": false,
       "plotOptions": {
        "customPlotOptions": {},
        "displayType": "table",
        "pivotAggregation": null,
        "pivotColumns": null,
        "xColumns": null,
        "yColumns": null
       },
       "removedWidgets": [],
       "schema": [
        {
         "metadata": "{}",
         "name": "job_id",
         "type": "\"long\""
        },
        {
         "metadata": "{}",
         "name": "company_name",
         "type": "\"string\""
        },
        {
         "metadata": "{}",
         "name": "title",
         "type": "\"string\""
        },
        {
         "metadata": "{}",
         "name": "description",
         "type": "\"string\""
        },
        {
         "metadata": "{}",
         "name": "max_salary",
         "type": "\"double\""
        },
        {
         "metadata": "{}",
         "name": "pay_period",
         "type": "\"string\""
        },
        {
         "metadata": "{}",
         "name": "location",
         "type": "\"string\""
        },
        {
         "metadata": "{}",
         "name": "company_id",
         "type": "\"double\""
        },
        {
         "metadata": "{}",
         "name": "views",
         "type": "\"double\""
        },
        {
         "metadata": "{}",
         "name": "med_salary",
         "type": "\"double\""
        },
        {
         "metadata": "{}",
         "name": "min_salary",
         "type": "\"double\""
        },
        {
         "metadata": "{}",
         "name": "formatted_work_type",
         "type": "\"string\""
        },
        {
         "metadata": "{}",
         "name": "applies",
         "type": "\"double\""
        },
        {
         "metadata": "{}",
         "name": "original_listed_time",
         "type": "\"double\""
        },
        {
         "metadata": "{}",
         "name": "remote_allowed",
         "type": "\"double\""
        },
        {
         "metadata": "{}",
         "name": "job_posting_url",
         "type": "\"string\""
        },
        {
         "metadata": "{}",
         "name": "application_url",
         "type": "\"string\""
        },
        {
         "metadata": "{}",
         "name": "application_type",
         "type": "\"string\""
        },
        {
         "metadata": "{}",
         "name": "expiry",
         "type": "\"double\""
        },
        {
         "metadata": "{}",
         "name": "closed_time",
         "type": "\"double\""
        },
        {
         "metadata": "{}",
         "name": "formatted_experience_level",
         "type": "\"string\""
        },
        {
         "metadata": "{}",
         "name": "skills_desc",
         "type": "\"string\""
        },
        {
         "metadata": "{}",
         "name": "listed_time",
         "type": "\"double\""
        },
        {
         "metadata": "{}",
         "name": "posting_domain",
         "type": "\"string\""
        },
        {
         "metadata": "{}",
         "name": "sponsored",
         "type": "\"long\""
        },
        {
         "metadata": "{}",
         "name": "work_type",
         "type": "\"string\""
        },
        {
         "metadata": "{}",
         "name": "currency",
         "type": "\"string\""
        },
        {
         "metadata": "{}",
         "name": "compensation_type",
         "type": "\"string\""
        },
        {
         "metadata": "{}",
         "name": "normalized_salary",
         "type": "\"double\""
        },
        {
         "metadata": "{}",
         "name": "zip_code",
         "type": "\"long\""
        },
        {
         "metadata": "{}",
         "name": "fips",
         "type": "\"long\""
        }
       ],
       "type": "table"
      }
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "%sql\n",
    "CREATE OR REPLACE FUNCTION fastest_way_to_double_salary(skillset STRING, current_sal FLOAT)\n",
    "RETURNS TABLE \n",
    "COMMENT 'Provides strategies to double salary based on role and industry trends.'\n",
    "RETURN\n",
    "SELECT * FROM posting.posting_schema.postings \n",
    "  WHERE (skills_desc Like CONCAT(\"%\", skillset, \"%\") OR description Like CONCAT(\"%\", skillset, \"%\"))\n",
    "  AND (max_salary >= current_sal * 1.5)\n",
    "  LIMIT 10;\n",
    "\n",
    "SELECT * FROM fastest_way_to_double_salary('python', 40000);"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "implicitDf": true,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "0ae7d6a8-0d6f-4477-8940-244e0bdf6c9b",
     "showTitle": false,
     "tableResultSettingsMap": {},
     "title": ""
    }
   },
   "outputs": [
    {
     "output_type": "display_data",
     "data": {
      "text/html": [
       "<style scoped>\n",
       "  .table-result-container {\n",
       "    max-height: 300px;\n",
       "    overflow: auto;\n",
       "  }\n",
       "  table, th, td {\n",
       "    border: 1px solid black;\n",
       "    border-collapse: collapse;\n",
       "  }\n",
       "  th, td {\n",
       "    padding: 5px;\n",
       "  }\n",
       "  th {\n",
       "    text-align: left;\n",
       "  }\n",
       "</style><div class='table-result-container'><table class='table-result'><thead style='background-color: white'><tr><th>industry_median_salary</th><th>industry_75th_percentile</th><th>industry_25th_percentile</th></tr></thead><tbody><tr><td>55.0</td><td>65000.0</td><td>27.0</td></tr></tbody></table></div>"
      ]
     },
     "metadata": {
      "application/vnd.databricks.v1+output": {
       "addedWidgets": {},
       "aggData": [],
       "aggError": "",
       "aggOverflow": false,
       "aggSchema": [],
       "aggSeriesLimitReached": false,
       "aggType": "",
       "arguments": {},
       "columnCustomDisplayInfos": {},
       "data": [
        [
         55.0,
         65000.0,
         27.0
        ]
       ],
       "datasetInfos": [
        {
         "name": "_sqldf",
         "schema": {
          "fields": [
           {
            "metadata": {},
            "name": "industry_median_salary",
            "nullable": true,
            "type": "double"
           },
           {
            "metadata": {},
            "name": "industry_75th_percentile",
            "nullable": true,
            "type": "double"
           },
           {
            "metadata": {},
            "name": "industry_25th_percentile",
            "nullable": true,
            "type": "double"
           }
          ],
          "type": "struct"
         },
         "tableIdentifier": null,
         "typeStr": "pyspark.sql.connect.dataframe.DataFrame"
        }
       ],
       "dbfsResultPath": null,
       "isJsonSchema": true,
       "metadata": {
        "createTempViewForImplicitDf": true,
        "dataframeName": "_sqldf",
        "executionCount": 128
       },
       "overflow": false,
       "plotOptions": {
        "customPlotOptions": {},
        "displayType": "table",
        "pivotAggregation": null,
        "pivotColumns": null,
        "xColumns": null,
        "yColumns": null
       },
       "removedWidgets": [],
       "schema": [
        {
         "metadata": "{}",
         "name": "industry_median_salary",
         "type": "\"double\""
        },
        {
         "metadata": "{}",
         "name": "industry_75th_percentile",
         "type": "\"double\""
        },
        {
         "metadata": "{}",
         "name": "industry_25th_percentile",
         "type": "\"double\""
        }
       ],
       "type": "table"
      }
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "%sql\n",
    "CREATE OR REPLACE FUNCTION compare_salary_to_industry(role STRING, location STRING)\n",
    "RETURNS TABLE (\n",
    "    industry_median_salary DOUBLE, \n",
    "    industry_75th_percentile DOUBLE, \n",
    "    industry_25th_percentile DOUBLE\n",
    "    -- top_companies STRING\n",
    ")\n",
    "COMMENT 'Compares salary for a given role and location with industry benchmarks from job postings.'\n",
    "RETURN\n",
    "SELECT \n",
    "    PERCENTILE_APPROX(med_salary, 0.5) AS industry_median_salary,\n",
    "    PERCENTILE_APPROX(med_salary, 0.75) AS industry_75th_percentile,\n",
    "    PERCENTILE_APPROX(med_salary, 0.25) AS industry_25th_percentile\n",
    "    \n",
    "FROM posting.posting_schema.postings\n",
    "WHERE (title LIKE CONCAT('%',role,'%') OR description LIKE  CONCAT('%',role,'%')) AND med_salary IS NOT NULL AND location = location;\n",
    "SELECT * FROM compare_salary_to_industry(\"data science\", \"New York\");"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {},
     "inputWidgets": {},
     "nuid": "b434fbcd-39ba-4386-ba20-e86828aaef8e",
     "showTitle": false,
     "tableResultSettingsMap": {},
     "title": ""
    }
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "application/vnd.databricks.v1+notebook": {
   "computePreferences": null,
   "dashboards": [],
   "environmentMetadata": {
    "base_environment": "",
    "environment_version": "2"
   },
   "inputWidgetPreferences": null,
   "language": "python",
   "notebookMetadata": {
    "mostRecentlyExecutedCommandWithImplicitDF": {
     "commandId": 8700722185336379,
     "dataframes": [
      "_sqldf"
     ]
    },
    "pythonIndentUnit": 4
   },
   "notebookName": "StevensQuackHacks",
   "widgets": {}
  },
  "language_info": {
   "name": "python"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 0
}